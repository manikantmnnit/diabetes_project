{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummy dataset\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import torch\n",
    "from torch import Generator\n",
    "from torch.utils.data import DataLoader,Dataset, dataloader,random_split\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "\n",
    "import dagshub\n",
    "import mlflow\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "\n",
    "# hp tunning library\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.logger.aim import AimLoggerCallback\n",
    "\n",
    "from aim import Run\n",
    "from aim.pytorch import track_params_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2026-01-23 04:01:10--  https://raw.githubusercontent.com/npradaschnor/Pima-Indians-Diabetes-Dataset/master/diabetes.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 23105 (23K) [text/plain]\n",
      "Saving to: ‚Äòdiabetes.csv.6‚Äô\n",
      "\n",
      "diabetes.csv.6      100%[===================>]  22.56K  --.-KB/s    in 0s      \n",
      "\n",
      "2026-01-23 04:01:10 (152 MB/s) - ‚Äòdiabetes.csv.6‚Äô saved [23105/23105]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/npradaschnor/Pima-Indians-Diabetes-Dataset/master/diabetes.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = \"https://raw.githubusercontent.com/npradaschnor/Pima-Indians-Diabetes-Dataset/master/diabetes.csv\"\n",
    "\n",
    "# Read the data\n",
    "df = pd.read_csv(url)\n",
    "df.head()\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DiabeticDataset(Dataset):\n",
    "    X:torch.Tensor\n",
    "    y:torch.Tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        return self.X[idx],self.y[idx]\n",
    "\n",
    "# normalization\n",
    "class Normalization_dataset(Dataset):\n",
    "    def __init__(self, base_dataset, mean, std):\n",
    "        self.base_dataset = base_dataset\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "        # üî• preserve indices if base_dataset is a Subset\n",
    "        if hasattr(base_dataset, \"indices\"):\n",
    "            self.indices = base_dataset.indices\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X, y = self.base_dataset[idx]\n",
    "        X = (X - self.mean) / (self.std + 1e-8)\n",
    "        return X, y\n",
    "\n",
    "class DiabeticDataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        batch_size=16,\n",
    "        train_ratio=0.7,\n",
    "        val_ratio=0.15,\n",
    "        seed=40\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.batch_size = batch_size\n",
    "        self.train_ratio = train_ratio\n",
    "        self.val_ratio = val_ratio\n",
    "        self.seed = seed\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        X = self.df.drop(columns=\"Outcome\", axis=1).values\n",
    "        y = self.df[\"Outcome\"].values\n",
    "\n",
    "        # convert into tensors\n",
    "        X = torch.tensor(X, dtype=torch.float32)\n",
    "        y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "        full_dataset = DiabeticDataset(X, y)\n",
    "\n",
    "        n_total = len(full_dataset)\n",
    "        n_train = int(self.train_ratio * n_total)\n",
    "        n_val   = int(self.val_ratio * n_total)\n",
    "        n_test  = n_total - n_train - n_val\n",
    "\n",
    "        generator = torch.Generator().manual_seed(self.seed)\n",
    "\n",
    "        self.train_ds, self.val_ds, self.test_ds = random_split(\n",
    "            full_dataset,\n",
    "            [n_train, n_val, n_test],\n",
    "            generator=generator\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_ds,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            pin_memory=True,\n",
    "            drop_last=False\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_ds,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            pin_memory=True,\n",
    "            drop_last=False\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_ds,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            pin_memory=True,\n",
    "            drop_last=False\n",
    "        )\n",
    "\n",
    "    # ---------- Normalization (fit on train only) ----------\n",
    "    def normalize_datasets(self):\n",
    "        X_all = []\n",
    "\n",
    "        for X, y in self.train_dataloader():\n",
    "            X_all.append(X.cpu())\n",
    "\n",
    "        X_all = torch.cat(X_all, dim=0)\n",
    "\n",
    "        mean = X_all.mean(dim=0)\n",
    "        std  = X_all.std(dim=0)\n",
    "\n",
    "        # Wrap datasets\n",
    "        self.train_ds = Normalization_dataset(self.train_ds, mean, std)\n",
    "        self.val_ds   = Normalization_dataset(self.val_ds,   mean, std)\n",
    "        self.test_ds  = Normalization_dataset(self.test_ds,  mean, std)\n",
    "\n",
    "        return mean, std\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: tensor([  3.8827, 120.9534,  69.1899,  19.9590,  77.6369,  31.8946,   0.4689,\n",
      "         33.2737])\n",
      "Std: tensor([  3.3960,  32.1912,  19.6791,  16.0622, 112.1099,   7.9516,   0.3178,\n",
      "         11.5753])\n"
     ]
    }
   ],
   "source": [
    "dm = DiabeticDataModule(df=df, seed=36)\n",
    "dm.setup()\n",
    "\n",
    "mean, std = dm.normalize_datasets()\n",
    "\n",
    "train_loader = dm.train_dataloader()\n",
    "test_loader  = dm.test_dataloader()\n",
    "valid_loader=dm.val_dataloader()\n",
    "\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Std:\", std)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 8]), torch.Size([16]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify the dataset\n",
    "type(dm.train_ds[0][1])\n",
    "X,y=next(iter(train_loader))\n",
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect train data\n",
    "X_train_list = []\n",
    "y_train_list = []\n",
    "\n",
    "for x, y in train_loader.dataset:\n",
    "    X_train_list.append(x)\n",
    "    y_train_list.append(y)\n",
    "\n",
    "X_train = torch.stack(X_train_list, dim=0)  # (N_train, num_features)\n",
    "y_train = torch.tensor(y_train_list)         # (N_train,)\n",
    "\n",
    "# Collect test data\n",
    "X_test_list = []\n",
    "y_test_list = []\n",
    "\n",
    "for x, y in test_loader.dataset:\n",
    "    X_test_list.append(x)\n",
    "    y_test_list.append(y)\n",
    "\n",
    "X_test = torch.stack(X_test_list, dim=0)   # (N_test, num_features)\n",
    "y_test = torch.tensor(y_test_list)    \n",
    "\n",
    "from pathlib import Path\n",
    "save_dir=Path.cwd().parent/'data'/'splits'\n",
    "save_dir.mkdir(parents=True,exist_ok=True)\n",
    "\n",
    "# File path\n",
    "save_path = save_dir / \"diabetes_normalized.pt\"\n",
    "\n",
    "torch.save({\n",
    "    \"X_train\": X_train,\n",
    "    \"y_train\": y_train,\n",
    "    \"X_test\": X_test,\n",
    "    \"y_test\": y_test\n",
    "}, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save split data inot csv and store in dvc\n",
    "train_indices=dm.train_ds.indices\n",
    "test_indices=dm.test_ds.indices\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "data_dir=Path.cwd().parent/'data'\n",
    "# Create 'splits' folder inside 'data' directory\n",
    "splits_dir = data_dir / 'splits'\n",
    "\n",
    "splits_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df.iloc[train_indices].to_csv(splits_dir / 'train.csv', index=False)\n",
    "df.iloc[test_indices].to_csv(splits_dir / 'test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# basic algo: logistic_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic algo: logistic Algorithm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LogisticRgressionModel(nn.Module):\n",
    "    def __init__(self, featur_dim):\n",
    "        super().__init__()\n",
    "        self.linear=nn.Linear(featur_dim,1)   # single output either 0 or 1\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# setup model , loss and optimizer\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "featur_dim=8\n",
    "\n",
    "model=LogisticRgressionModel(featur_dim=featur_dim)\n",
    "\n",
    "lr=0.001\n",
    "\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=lr)\n",
    "\n",
    "criterion=nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct=0\n",
    "    total=0\n",
    "\n",
    "    for X, y in loader:\n",
    "        X = X.to(device)\n",
    "        y = y.float().unsqueeze(1).to(device)  # (batch, 1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X)\n",
    "        loss = criterion(logits, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # accuracy\n",
    "        probs=torch.sigmoid(logits)\n",
    "        predicts=(probs>0.5).long()\n",
    "        correct += (predicts == y.long()).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "\n",
    "    return total_loss / len(loader),correct/total\n",
    "\n",
    "def evaluate(model,loader,device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in loader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            logits = model(X)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            preds = (probs > 0.5).long().squeeze(1)\n",
    "\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "    return correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as manikantmnnit\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as manikantmnnit\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"manikantmnnit/diabetes_project\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"manikantmnnit/diabetes_project\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository manikantmnnit/diabetes_project initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository manikantmnnit/diabetes_project initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50] | Loss: 0.6972 | Train Acc: 0.5587 | Test Acc: 0.5259\n",
      "Epoch [10/50] | Loss: 0.6339 | Train Acc: 0.6760 | Test Acc: 0.6552\n",
      "Epoch [15/50] | Loss: 0.5906 | Train Acc: 0.7300 | Test Acc: 0.7069\n",
      "Epoch [20/50] | Loss: 0.5659 | Train Acc: 0.7486 | Test Acc: 0.7069\n",
      "Epoch [25/50] | Loss: 0.5422 | Train Acc: 0.7449 | Test Acc: 0.7241\n",
      "Epoch [30/50] | Loss: 0.5240 | Train Acc: 0.7467 | Test Acc: 0.7414\n",
      "Epoch [35/50] | Loss: 0.5127 | Train Acc: 0.7393 | Test Acc: 0.7586\n",
      "Epoch [40/50] | Loss: 0.5072 | Train Acc: 0.7561 | Test Acc: 0.7672\n",
      "Epoch [45/50] | Loss: 0.5015 | Train Acc: 0.7561 | Test Acc: 0.7672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/26 15:52:54 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50] | Loss: 0.4938 | Train Acc: 0.7598 | Test Acc: 0.7672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/26 15:53:02 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cu128) contains a local version label (+cu128). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2026/01/26 15:53:10 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.23.0+cu128) contains a local version label (+cu128). MLflow logged a pip requirement for this package as 'torchvision==0.23.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run log_reg_baseline at: https://dagshub.com/manikantmnnit/diabetes_project.mlflow/#/experiments/0/runs/2d183cc7bfdc4a84b8ff0bb1ed7cde4e\n",
      "üß™ View experiment at: https://dagshub.com/manikantmnnit/diabetes_project.mlflow/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "import dagshub\n",
    "dagshub.init(repo_owner='manikantmnnit', repo_name='diabetes_project', mlflow=True)\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri('https://dagshub.com/manikantmnnit/diabetes_project.mlflow')\n",
    "\n",
    "num_epochs = 50\n",
    "mlflow.set_experiment(\"diabetes_logistic_regression\")\n",
    "with mlflow.start_run(run_name='log_reg_baseline'):\n",
    "    mlflow.log_param(\"model\", \"logistic_regression\")\n",
    "    mlflow.log_param(\"optimizer\", \"Adam\")\n",
    "    mlflow.log_param(\"learning_rate\", lr)\n",
    "    mlflow.log_param('Batch_size',num_epochs)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss,train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        test_acc   = evaluate(model, test_loader, device)\n",
    "\n",
    "        # ---- Log metrics per epoch ----\n",
    "        mlflow.log_metric(\"train_log_loss\", train_loss, step=epoch)\n",
    "        mlflow.log_metric(\"train_accuracy\", train_acc, step=epoch)\n",
    "        mlflow.log_metric(\"test_accuracy\", test_acc, step=epoch)\n",
    "\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch+1}/{num_epochs}] | \"\n",
    "                f\"Loss: {train_loss:.4f} | \"\n",
    "                f\"Train Acc: {train_acc:.4f} | \"\n",
    "                f\"Test Acc: {test_acc:.4f}\"\n",
    "            )\n",
    "    \n",
    "    # log model\n",
    "    mlflow.pytorch.log_model(model,artifact_path='model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Ray Tune for HP tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "\n",
    "def train_using_tune(config,  model_cls, feature_dim,df):\n",
    "\n",
    "    device = config[\"device\"]\n",
    "    batch_size = int(config[\"batch_size\"])\n",
    "    lr = config[\"lr\"]\n",
    "\n",
    "    # üîπ Build DataModule INSIDE trial\n",
    "    dm = DiabeticDataModule(\n",
    "        df=df,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    dm.setup()\n",
    "    dm.normalize_datasets()\n",
    "\n",
    "    train_loader = dm.train_dataloader()\n",
    "    valid_loader = dm.val_dataloader()\n",
    "    test_loader  = dm.test_dataloader()\n",
    "\n",
    "    # Build model\n",
    "    model = model_cls(feature_dim).to(device)\n",
    "\n",
    "    # üîπ optimizer\n",
    "    if config[\"optimizer\"] == \"adam\":\n",
    "        optimizer = torch.optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr=config[\"lr\"],\n",
    "            weight_decay=config[\"weight_decay\"]\n",
    "        )\n",
    "    else:\n",
    "        optimizer = torch.optim.SGD(\n",
    "            model.parameters(),\n",
    "            lr=config[\"lr\"],\n",
    "            momentum=0.9,\n",
    "            weight_decay=config[\"weight_decay\"]\n",
    "        )\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # ----- Restore checkpoint if exists -----\n",
    "    checkpoint = tune.get_checkpoint()\n",
    "    if checkpoint:\n",
    "        with checkpoint.as_directory() as ckpt_dir:\n",
    "            model_state, optimizer_state = torch.load(\n",
    "                os.path.join(ckpt_dir, \"checkpoint.pt\"),\n",
    "                map_location=device\n",
    "            )\n",
    "            model.load_state_dict(model_state)\n",
    "            optimizer.load_state_dict(optimizer_state)\n",
    "\n",
    "    # ----- Training loop -----\n",
    "    max_epochs = config[\"max_num_epochs\"]\n",
    "    for epoch in range(max_epochs):\n",
    "\n",
    "        # ===== Train =====\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        for X, y in train_loader:\n",
    "            X = X.to(device)\n",
    "            y = y.float().unsqueeze(1).to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(X) # forward\n",
    "            loss = criterion(logits, y)\n",
    "\n",
    "            loss.backward()  # back propagation\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "            probs = torch.sigmoid(logits)\n",
    "            preds = (probs > 0.5).long()\n",
    "            correct_train += (preds == y.long()).sum().item()\n",
    "            total_train += y.size(0)\n",
    "\n",
    "        train_loss = total_train_loss / len(train_loader)\n",
    "        train_acc = correct_train / total_train\n",
    "\n",
    "        # ===== Validation =====\n",
    "        model.eval()\n",
    "        total_val_loss = 0.0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X, y in valid_loader:\n",
    "                X = X.to(device)\n",
    "                y = y.float().unsqueeze(1).to(device)\n",
    "\n",
    "                logits = model(X)\n",
    "                loss = criterion(logits, y)\n",
    "\n",
    "                total_val_loss += loss.item()\n",
    "\n",
    "                probs = torch.sigmoid(logits)\n",
    "                preds = (probs > 0.5).long()\n",
    "                correct_val += (preds == y.long()).sum().item()\n",
    "                total_val += y.size(0)\n",
    "\n",
    "        val_loss = total_val_loss / len(valid_loader)\n",
    "        val_acc = correct_val / total_val\n",
    "\n",
    "        # ===== Save checkpoint + report =====\n",
    "        with tempfile.TemporaryDirectory() as temp_checkpoint_dir:\n",
    "            ckpt_path = os.path.join(temp_checkpoint_dir, \"checkpoint.pt\")\n",
    "            torch.save((model.state_dict(), optimizer.state_dict()), ckpt_path)\n",
    "\n",
    "            checkpoint = tune.Checkpoint.from_directory(temp_checkpoint_dir)\n",
    "\n",
    "            tune.report(\n",
    "                {\n",
    "                    \"train_loss\": train_loss,\n",
    "                    \"train_accuracy\": train_acc,\n",
    "                    \"val_loss\": val_loss,\n",
    "                    \"val_accuracy\": val_acc,\n",
    "                },\n",
    "                checkpoint=checkpoint\n",
    "            )\n",
    "\n",
    "\n",
    "# obtain best accurac based on best model uisng checkpoint\n",
    "def test_best_model(best_result, model_cls, feature_dim, df):\n",
    "\n",
    "    device = best_result.config[\"device\"]\n",
    "\n",
    "    # üîπ Rebuild DataModule\n",
    "    dm = DiabeticDataModule(df=df, batch_size=best_result.config[\"batch_size\"])\n",
    "    dm.setup()\n",
    "    dm.normalize_datasets()\n",
    "\n",
    "    test_loader = dm.test_dataloader()\n",
    "\n",
    "    # üîπ Build model\n",
    "    best_trained_model = model_cls(feature_dim).to(device)\n",
    "\n",
    "    # ----- Load best checkpoint -----\n",
    "    checkpoint = best_result.checkpoint\n",
    "    with checkpoint.as_directory() as ckpt_dir:\n",
    "        checkpoint_path = os.path.join(ckpt_dir, \"checkpoint.pt\")\n",
    "        model_state, _ = torch.load(checkpoint_path, map_location=device)\n",
    "\n",
    "    best_trained_model.load_state_dict(model_state)\n",
    "    best_trained_model.eval()\n",
    "\n",
    "    # ----- Test loop -----\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_loader:\n",
    "            X = X.to(device)\n",
    "            y = y.float().unsqueeze(1).to(device)\n",
    "\n",
    "            logits = best_trained_model(X)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            preds = (probs > 0.5).long()\n",
    "\n",
    "            correct_test += (preds == y.long()).sum().item()\n",
    "            total_test += y.size(0)\n",
    "\n",
    "    print(f\"‚úÖ Best trial test accuracy: {correct_test / total_test:.4f}\")\n",
    "\n",
    "\n",
    "# train the model, find best performing one and load the trained netqork from checkpoint file\n",
    "\n",
    "def main(config,  model_cls,df, feature_dim, gpus_per_trial=1):\n",
    "\n",
    "    \n",
    "    scheduler = ASHAScheduler(\n",
    "        time_attr=\"training_iteration\",\n",
    "        max_t=config[\"max_num_epochs\"],\n",
    "        grace_period=1,\n",
    "        reduction_factor=2\n",
    "    )\n",
    "\n",
    "    tuner = tune.Tuner(\n",
    "        tune.with_resources(\n",
    "            tune.with_parameters(\n",
    "                train_using_tune,\n",
    "                model_cls=model_cls,\n",
    "                feature_dim=feature_dim,\n",
    "                df=df\n",
    "            ),\n",
    "            resources={\"cpu\": 4, \"gpu\": gpus_per_trial}\n",
    "        ),\n",
    "        tune_config=tune.TuneConfig(\n",
    "            metric=\"val_loss\",\n",
    "            mode=\"min\",\n",
    "            scheduler=scheduler,\n",
    "            num_samples=config[\"num_trials\"],\n",
    "        ),\n",
    "        param_space=config,\n",
    "    )\n",
    "\n",
    "    results = tuner.fit()\n",
    "\n",
    "    best_result = results.get_best_result(\"val_loss\", \"min\")\n",
    "\n",
    "    print(f\"üèÜ Best trial config: {best_result.config}\")\n",
    "    print(f\"üèÜ Best trial final validation loss: {best_result.metrics['val_loss']}\")\n",
    "    print(f\"üèÜ Best trial final validation accuracy: {best_result.metrics['val_accuracy']}\")\n",
    "\n",
    "    test_best_model(best_result, model_cls, feature_dim, df)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_using_tune pid=36212)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00000_0_batch_size=32,lr=0.0148,optimizer=sgd,weight_decay=0.0086_2026-01-28_14-06-05/checkpoint_000000)\n",
      "\u001b[36m(train_using_tune pid=36212)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00000_0_batch_size=32,lr=0.0148,optimizer=sgd,weight_decay=0.0086_2026-01-28_14-06-05/checkpoint_000001)\n",
      "\u001b[36m(train_using_tune pid=36212)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00000_0_batch_size=32,lr=0.0148,optimizer=sgd,weight_decay=0.0086_2026-01-28_14-06-05/checkpoint_000002)\n",
      "\u001b[36m(train_using_tune pid=36212)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00000_0_batch_size=32,lr=0.0148,optimizer=sgd,weight_decay=0.0086_2026-01-28_14-06-05/checkpoint_000003)\n",
      "\u001b[36m(train_using_tune pid=36212)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00000_0_batch_size=32,lr=0.0148,optimizer=sgd,weight_decay=0.0086_2026-01-28_14-06-05/checkpoint_000004)\n",
      "\u001b[36m(train_using_tune pid=36212)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00000_0_batch_size=32,lr=0.0148,optimizer=sgd,weight_decay=0.0086_2026-01-28_14-06-05/checkpoint_000005)\n",
      "\u001b[36m(train_using_tune pid=36212)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00000_0_batch_size=32,lr=0.0148,optimizer=sgd,weight_decay=0.0086_2026-01-28_14-06-05/checkpoint_000006)\n",
      "\u001b[36m(train_using_tune pid=36212)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00000_0_batch_size=32,lr=0.0148,optimizer=sgd,weight_decay=0.0086_2026-01-28_14-06-05/checkpoint_000007)\n",
      "\u001b[36m(train_using_tune pid=36212)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00000_0_batch_size=32,lr=0.0148,optimizer=sgd,weight_decay=0.0086_2026-01-28_14-06-05/checkpoint_000008)\n",
      "\u001b[36m(train_using_tune pid=36212)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00000_0_batch_size=32,lr=0.0148,optimizer=sgd,weight_decay=0.0086_2026-01-28_14-06-05/checkpoint_000009)\n",
      "\u001b[36m(train_using_tune pid=36212)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00000_0_batch_size=32,lr=0.0148,optimizer=sgd,weight_decay=0.0086_2026-01-28_14-06-05/checkpoint_000010)\n",
      "\u001b[36m(train_using_tune pid=36212)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00000_0_batch_size=32,lr=0.0148,optimizer=sgd,weight_decay=0.0086_2026-01-28_14-06-05/checkpoint_000011)\n",
      "\u001b[36m(train_using_tune pid=36212)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00000_0_batch_size=32,lr=0.0148,optimizer=sgd,weight_decay=0.0086_2026-01-28_14-06-05/checkpoint_000012)\n",
      "\u001b[36m(train_using_tune pid=36212)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00000_0_batch_size=32,lr=0.0148,optimizer=sgd,weight_decay=0.0086_2026-01-28_14-06-05/checkpoint_000013)\n",
      "\u001b[36m(train_using_tune pid=36212)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00000_0_batch_size=32,lr=0.0148,optimizer=sgd,weight_decay=0.0086_2026-01-28_14-06-05/checkpoint_000014)\n",
      "\u001b[36m(train_using_tune pid=36212)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00000_0_batch_size=32,lr=0.0148,optimizer=sgd,weight_decay=0.0086_2026-01-28_14-06-05/checkpoint_000015)\n",
      "\u001b[36m(train_using_tune pid=36212)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00000_0_batch_size=32,lr=0.0148,optimizer=sgd,weight_decay=0.0086_2026-01-28_14-06-05/checkpoint_000016)\n",
      "\u001b[36m(train_using_tune pid=36212)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00000_0_batch_size=32,lr=0.0148,optimizer=sgd,weight_decay=0.0086_2026-01-28_14-06-05/checkpoint_000017)\n",
      "\u001b[36m(train_using_tune pid=36212)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00000_0_batch_size=32,lr=0.0148,optimizer=sgd,weight_decay=0.0086_2026-01-28_14-06-05/checkpoint_000018)\n",
      "\u001b[36m(train_using_tune pid=36212)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00000_0_batch_size=32,lr=0.0148,optimizer=sgd,weight_decay=0.0086_2026-01-28_14-06-05/checkpoint_000019)\n",
      "\u001b[36m(train_using_tune pid=36212)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00000_0_batch_size=32,lr=0.0148,optimizer=sgd,weight_decay=0.0086_2026-01-28_14-06-05/checkpoint_000020)\n",
      "\u001b[36m(train_using_tune pid=36212)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00000_0_batch_size=32,lr=0.0148,optimizer=sgd,weight_decay=0.0086_2026-01-28_14-06-05/checkpoint_000021)\n",
      "\u001b[36m(train_using_tune pid=36212)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00000_0_batch_size=32,lr=0.0148,optimizer=sgd,weight_decay=0.0086_2026-01-28_14-06-05/checkpoint_000022)\n",
      "\u001b[36m(train_using_tune pid=36212)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00000_0_batch_size=32,lr=0.0148,optimizer=sgd,weight_decay=0.0086_2026-01-28_14-06-05/checkpoint_000023)\n",
      "\u001b[36m(train_using_tune pid=36212)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00000_0_batch_size=32,lr=0.0148,optimizer=sgd,weight_decay=0.0086_2026-01-28_14-06-05/checkpoint_000024)\n",
      "\u001b[36m(train_using_tune pid=36212)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00000_0_batch_size=32,lr=0.0148,optimizer=sgd,weight_decay=0.0086_2026-01-28_14-06-05/checkpoint_000025)\n",
      "\u001b[36m(train_using_tune pid=36212)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00000_0_batch_size=32,lr=0.0148,optimizer=sgd,weight_decay=0.0086_2026-01-28_14-06-05/checkpoint_000026)\n",
      "\u001b[36m(train_using_tune pid=36212)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00000_0_batch_size=32,lr=0.0148,optimizer=sgd,weight_decay=0.0086_2026-01-28_14-06-05/checkpoint_000027)\n",
      "\u001b[36m(train_using_tune pid=36212)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00000_0_batch_size=32,lr=0.0148,optimizer=sgd,weight_decay=0.0086_2026-01-28_14-06-05/checkpoint_000028)\n",
      "\u001b[36m(train_using_tune pid=36212)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00000_0_batch_size=32,lr=0.0148,optimizer=sgd,weight_decay=0.0086_2026-01-28_14-06-05/checkpoint_000029)\n",
      "\u001b[36m(train_using_tune pid=37030)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00001_1_batch_size=64,lr=0.0042,optimizer=adam,weight_decay=0.0074_2026-01-28_14-06-05/checkpoint_000000)\n",
      "\u001b[36m(train_using_tune pid=37837)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00002_2_batch_size=16,lr=0.0027,optimizer=sgd,weight_decay=0.0001_2026-01-28_14-06-05/checkpoint_000000)\n",
      "\u001b[36m(train_using_tune pid=38656)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00003_3_batch_size=64,lr=0.0736,optimizer=sgd,weight_decay=0.0005_2026-01-28_14-06-05/checkpoint_000001)\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(train_using_tune pid=39812)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00004_4_batch_size=64,lr=0.0122,optimizer=sgd,weight_decay=0.0000_2026-01-28_14-06-05/checkpoint_000000)\n",
      "\u001b[36m(train_using_tune pid=40618)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00005_5_batch_size=16,lr=0.0003,optimizer=adam,weight_decay=0.0000_2026-01-28_14-06-05/checkpoint_000000)\n",
      "\u001b[36m(train_using_tune pid=40618)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00005_5_batch_size=16,lr=0.0003,optimizer=adam,weight_decay=0.0000_2026-01-28_14-06-05/checkpoint_000001)\n",
      "\u001b[36m(train_using_tune pid=41421)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00006_6_batch_size=16,lr=0.0140,optimizer=sgd,weight_decay=0.0001_2026-01-28_14-06-05/checkpoint_000000)\n",
      "\u001b[36m(train_using_tune pid=42225)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00007_7_batch_size=32,lr=0.0041,optimizer=sgd,weight_decay=0.0000_2026-01-28_14-06-05/checkpoint_000000)\n",
      "\u001b[36m(train_using_tune pid=43023)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00008_8_batch_size=64,lr=0.0082,optimizer=sgd,weight_decay=0.0092_2026-01-28_14-06-05/checkpoint_000000)\n",
      "\u001b[36m(train_using_tune pid=43826)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00009_9_batch_size=32,lr=0.0772,optimizer=sgd,weight_decay=0.0000_2026-01-28_14-06-05/checkpoint_000000)\n",
      "\u001b[36m(train_using_tune pid=43826)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00009_9_batch_size=32,lr=0.0772,optimizer=sgd,weight_decay=0.0000_2026-01-28_14-06-05/checkpoint_000001)\n",
      "\u001b[36m(train_using_tune pid=43826)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00009_9_batch_size=32,lr=0.0772,optimizer=sgd,weight_decay=0.0000_2026-01-28_14-06-05/checkpoint_000002)\n",
      "\u001b[36m(train_using_tune pid=43826)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00009_9_batch_size=32,lr=0.0772,optimizer=sgd,weight_decay=0.0000_2026-01-28_14-06-05/checkpoint_000003)\n",
      "\u001b[36m(train_using_tune pid=43826)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00009_9_batch_size=32,lr=0.0772,optimizer=sgd,weight_decay=0.0000_2026-01-28_14-06-05/checkpoint_000004)\n",
      "\u001b[36m(train_using_tune pid=43826)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00009_9_batch_size=32,lr=0.0772,optimizer=sgd,weight_decay=0.0000_2026-01-28_14-06-05/checkpoint_000005)\n",
      "\u001b[36m(train_using_tune pid=43826)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00009_9_batch_size=32,lr=0.0772,optimizer=sgd,weight_decay=0.0000_2026-01-28_14-06-05/checkpoint_000006)\n",
      "\u001b[36m(train_using_tune pid=43826)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00009_9_batch_size=32,lr=0.0772,optimizer=sgd,weight_decay=0.0000_2026-01-28_14-06-05/checkpoint_000007)\n",
      "\u001b[36m(train_using_tune pid=43826)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00009_9_batch_size=32,lr=0.0772,optimizer=sgd,weight_decay=0.0000_2026-01-28_14-06-05/checkpoint_000008)\n",
      "\u001b[36m(train_using_tune pid=43826)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00009_9_batch_size=32,lr=0.0772,optimizer=sgd,weight_decay=0.0000_2026-01-28_14-06-05/checkpoint_000009)\n",
      "\u001b[36m(train_using_tune pid=43826)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00009_9_batch_size=32,lr=0.0772,optimizer=sgd,weight_decay=0.0000_2026-01-28_14-06-05/checkpoint_000010)\n",
      "\u001b[36m(train_using_tune pid=43826)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00009_9_batch_size=32,lr=0.0772,optimizer=sgd,weight_decay=0.0000_2026-01-28_14-06-05/checkpoint_000011)\n",
      "\u001b[36m(train_using_tune pid=43826)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00009_9_batch_size=32,lr=0.0772,optimizer=sgd,weight_decay=0.0000_2026-01-28_14-06-05/checkpoint_000012)\n",
      "\u001b[36m(train_using_tune pid=43826)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00009_9_batch_size=32,lr=0.0772,optimizer=sgd,weight_decay=0.0000_2026-01-28_14-06-05/checkpoint_000013)\n",
      "\u001b[36m(train_using_tune pid=43826)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00009_9_batch_size=32,lr=0.0772,optimizer=sgd,weight_decay=0.0000_2026-01-28_14-06-05/checkpoint_000014)\n",
      "\u001b[36m(train_using_tune pid=43826)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00009_9_batch_size=32,lr=0.0772,optimizer=sgd,weight_decay=0.0000_2026-01-28_14-06-05/checkpoint_000015)\n",
      "\u001b[36m(train_using_tune pid=44639)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00010_10_batch_size=16,lr=0.0057,optimizer=sgd,weight_decay=0.0000_2026-01-28_14-06-05/checkpoint_000000)\n",
      "\u001b[36m(train_using_tune pid=45642)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00011_11_batch_size=64,lr=0.0080,optimizer=sgd,weight_decay=0.0003_2026-01-28_14-06-05/checkpoint_000000)\n",
      "\u001b[36m(train_using_tune pid=46599)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00012_12_batch_size=16,lr=0.0527,optimizer=adam,weight_decay=0.0000_2026-01-28_14-06-05/checkpoint_000000)\n",
      "\u001b[36m(train_using_tune pid=46599)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00012_12_batch_size=16,lr=0.0527,optimizer=adam,weight_decay=0.0000_2026-01-28_14-06-05/checkpoint_000001)\n",
      "\u001b[36m(train_using_tune pid=47411)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00013_13_batch_size=32,lr=0.0006,optimizer=sgd,weight_decay=0.0070_2026-01-28_14-06-05/checkpoint_000000)\n",
      "\u001b[36m(train_using_tune pid=48224)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00014_14_batch_size=64,lr=0.0408,optimizer=adam,weight_decay=0.0000_2026-01-28_14-06-05/checkpoint_000000)\n",
      "\u001b[36m(train_using_tune pid=48224)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00014_14_batch_size=64,lr=0.0408,optimizer=adam,weight_decay=0.0000_2026-01-28_14-06-05/checkpoint_000001)\n",
      "\u001b[36m(train_using_tune pid=48224)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00014_14_batch_size=64,lr=0.0408,optimizer=adam,weight_decay=0.0000_2026-01-28_14-06-05/checkpoint_000002)\n",
      "\u001b[36m(train_using_tune pid=48224)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00014_14_batch_size=64,lr=0.0408,optimizer=adam,weight_decay=0.0000_2026-01-28_14-06-05/checkpoint_000003)\n",
      "\u001b[36m(train_using_tune pid=48224)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00014_14_batch_size=64,lr=0.0408,optimizer=adam,weight_decay=0.0000_2026-01-28_14-06-05/checkpoint_000004)\n",
      "\u001b[36m(train_using_tune pid=48224)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00014_14_batch_size=64,lr=0.0408,optimizer=adam,weight_decay=0.0000_2026-01-28_14-06-05/checkpoint_000005)\n",
      "\u001b[36m(train_using_tune pid=48224)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00014_14_batch_size=64,lr=0.0408,optimizer=adam,weight_decay=0.0000_2026-01-28_14-06-05/checkpoint_000006)\n",
      "\u001b[36m(train_using_tune pid=48224)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00014_14_batch_size=64,lr=0.0408,optimizer=adam,weight_decay=0.0000_2026-01-28_14-06-05/checkpoint_000007)\n",
      "\u001b[36m(train_using_tune pid=48224)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00014_14_batch_size=64,lr=0.0408,optimizer=adam,weight_decay=0.0000_2026-01-28_14-06-05/checkpoint_000008)\n",
      "\u001b[36m(train_using_tune pid=48224)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00014_14_batch_size=64,lr=0.0408,optimizer=adam,weight_decay=0.0000_2026-01-28_14-06-05/checkpoint_000009)\n",
      "\u001b[36m(train_using_tune pid=48224)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00014_14_batch_size=64,lr=0.0408,optimizer=adam,weight_decay=0.0000_2026-01-28_14-06-05/checkpoint_000010)\n",
      "\u001b[36m(train_using_tune pid=48224)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00014_14_batch_size=64,lr=0.0408,optimizer=adam,weight_decay=0.0000_2026-01-28_14-06-05/checkpoint_000011)\n",
      "\u001b[36m(train_using_tune pid=48224)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00014_14_batch_size=64,lr=0.0408,optimizer=adam,weight_decay=0.0000_2026-01-28_14-06-05/checkpoint_000012)\n",
      "\u001b[36m(train_using_tune pid=48224)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00014_14_batch_size=64,lr=0.0408,optimizer=adam,weight_decay=0.0000_2026-01-28_14-06-05/checkpoint_000013)\n",
      "\u001b[36m(train_using_tune pid=48224)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00014_14_batch_size=64,lr=0.0408,optimizer=adam,weight_decay=0.0000_2026-01-28_14-06-05/checkpoint_000014)\n",
      "\u001b[36m(train_using_tune pid=48224)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00014_14_batch_size=64,lr=0.0408,optimizer=adam,weight_decay=0.0000_2026-01-28_14-06-05/checkpoint_000015)\n",
      "\u001b[36m(train_using_tune pid=48224)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00014_14_batch_size=64,lr=0.0408,optimizer=adam,weight_decay=0.0000_2026-01-28_14-06-05/checkpoint_000016)\n",
      "\u001b[36m(train_using_tune pid=48224)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00014_14_batch_size=64,lr=0.0408,optimizer=adam,weight_decay=0.0000_2026-01-28_14-06-05/checkpoint_000017)\n",
      "\u001b[36m(train_using_tune pid=48224)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00014_14_batch_size=64,lr=0.0408,optimizer=adam,weight_decay=0.0000_2026-01-28_14-06-05/checkpoint_000018)\n",
      "\u001b[36m(train_using_tune pid=48224)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00014_14_batch_size=64,lr=0.0408,optimizer=adam,weight_decay=0.0000_2026-01-28_14-06-05/checkpoint_000019)\n",
      "\u001b[36m(train_using_tune pid=48224)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00014_14_batch_size=64,lr=0.0408,optimizer=adam,weight_decay=0.0000_2026-01-28_14-06-05/checkpoint_000020)\n",
      "\u001b[36m(train_using_tune pid=48224)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00014_14_batch_size=64,lr=0.0408,optimizer=adam,weight_decay=0.0000_2026-01-28_14-06-05/checkpoint_000021)\n",
      "\u001b[36m(train_using_tune pid=48224)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00014_14_batch_size=64,lr=0.0408,optimizer=adam,weight_decay=0.0000_2026-01-28_14-06-05/checkpoint_000022)\n",
      "\u001b[36m(train_using_tune pid=48224)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00014_14_batch_size=64,lr=0.0408,optimizer=adam,weight_decay=0.0000_2026-01-28_14-06-05/checkpoint_000023)\n",
      "\u001b[36m(train_using_tune pid=48224)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00014_14_batch_size=64,lr=0.0408,optimizer=adam,weight_decay=0.0000_2026-01-28_14-06-05/checkpoint_000024)\n",
      "\u001b[36m(train_using_tune pid=48224)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00014_14_batch_size=64,lr=0.0408,optimizer=adam,weight_decay=0.0000_2026-01-28_14-06-05/checkpoint_000025)\n",
      "\u001b[36m(train_using_tune pid=48224)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00014_14_batch_size=64,lr=0.0408,optimizer=adam,weight_decay=0.0000_2026-01-28_14-06-05/checkpoint_000026)\n",
      "\u001b[36m(train_using_tune pid=48224)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00014_14_batch_size=64,lr=0.0408,optimizer=adam,weight_decay=0.0000_2026-01-28_14-06-05/checkpoint_000027)\n",
      "\u001b[36m(train_using_tune pid=48224)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00014_14_batch_size=64,lr=0.0408,optimizer=adam,weight_decay=0.0000_2026-01-28_14-06-05/checkpoint_000028)\n",
      "2026-01-28 14:09:18,154\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05' in 0.0143s.\n",
      "2026-01-28 14:09:18,165\tINFO tune.py:1041 -- Total run time: 192.55 seconds (192.49 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÜ Best trial config: {'lr': 0.014751169373953247, 'batch_size': 32, 'optimizer': 'sgd', 'weight_decay': 0.008580864328817632, 'max_num_epochs': 30, 'device': 'cuda', 'num_trials': 15}\n",
      "üèÜ Best trial final validation loss: 0.5601386427879333\n",
      "üèÜ Best trial final validation accuracy: 0.7217391304347827\n",
      "‚úÖ Best trial test accuracy: 0.7241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_using_tune pid=48224)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_14-06-05/train_using_tune_7c987_00014_14_batch_size=64,lr=0.0408,optimizer=adam,weight_decay=0.0000_2026-01-28_14-06-05/checkpoint_000029)\n"
     ]
    }
   ],
   "source": [
    "config =  {\n",
    "    \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "    \"batch_size\": tune.choice([16, 32, 64]),\n",
    "    \"optimizer\": tune.choice([\"adam\", \"sgd\"]),\n",
    "    \"weight_decay\": tune.loguniform(1e-6, 1e-2),\n",
    "    \"max_num_epochs\": 30,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"num_trials\": 15,\n",
    "}\n",
    "\n",
    "main(\n",
    "    config=config,\n",
    "    df=df,\n",
    "    \n",
    "    model_cls=LogisticRgressionModel,\n",
    "    feature_dim=8,\n",
    "    gpus_per_trial=1 if torch.cuda.is_available() else 0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ray Tune + MLflowLoggerCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as manikantmnnit\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as manikantmnnit\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"manikantmnnit/diabetes_project\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"manikantmnnit/diabetes_project\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository manikantmnnit/diabetes_project initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository manikantmnnit/diabetes_project initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.air.integrations.mlflow import MLflowLoggerCallback\n",
    "\n",
    "\n",
    "import dagshub\n",
    "dagshub.init(repo_owner='manikantmnnit', repo_name='diabetes_project', mlflow=True)\n",
    "\n",
    "MLFLOW_TRACKING_URI='https://dagshub.com/manikantmnnit/diabetes_project.mlflow'\n",
    "\n",
    "\n",
    "EXPERIMENT_NAME = \"diabetes_ray_tune\"\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "def main(config, model_cls, df, feature_dim, gpus_per_trial=0):\n",
    "\n",
    "    scheduler = ASHAScheduler(\n",
    "        time_attr=\"training_iteration\",\n",
    "        max_t=config[\"max_num_epochs\"],\n",
    "        grace_period=1,\n",
    "        reduction_factor=2\n",
    "    )\n",
    "\n",
    "    tuner = tune.Tuner(\n",
    "        tune.with_resources(\n",
    "            tune.with_parameters(\n",
    "                train_using_tune,\n",
    "                model_cls=model_cls,\n",
    "                feature_dim=feature_dim,\n",
    "                df=df\n",
    "            ),\n",
    "            resources={\"cpu\": 4, \"gpu\": gpus_per_trial}\n",
    "        ),\n",
    "        tune_config=tune.TuneConfig(\n",
    "            metric=\"val_loss\",\n",
    "            mode=\"min\",\n",
    "            scheduler=scheduler,\n",
    "            num_samples=config[\"num_trials\"],\n",
    "        ),\n",
    "        run_config=tune.RunConfig(\n",
    "            name=\"ray_tune_diabetes\",\n",
    "            callbacks=[\n",
    "                MLflowLoggerCallback(\n",
    "                    tracking_uri=MLFLOW_TRACKING_URI,\n",
    "                    experiment_name=EXPERIMENT_NAME,\n",
    "                    save_artifact=True\n",
    "                )\n",
    "            ],\n",
    "        ),\n",
    "        param_space=config,\n",
    "    )\n",
    "\n",
    "    results = tuner.fit()\n",
    "\n",
    "    best_result = results.get_best_result(\"val_loss\", \"min\")\n",
    "\n",
    "    print(\"üèÜ Best config:\", best_result.config)\n",
    "    print(\"üèÜ Best val_loss:\", best_result.metrics[\"val_loss\"])\n",
    "    print(\"üèÜ Best val_accuracy:\", best_result.metrics[\"val_accuracy\"])\n",
    "\n",
    "    test_best_model(best_result, model_cls, feature_dim, df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_using_tune pid=52287)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00000_0_batch_size=16,lr=0.0012,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000000)\n",
      "2026-01-28 14:10:36,502\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 15.644 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:10:36,504\tWARNING util.py:201 -- The `process_trial_result` operation took 15.646 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:10:36,505\tWARNING util.py:201 -- Processing trial results took 15.647 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:10:36,505\tWARNING util.py:201 -- The `process_trial_result` operation took 15.647 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=52287)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00000_0_batch_size=16,lr=0.0012,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000001)\n",
      "\u001b[36m(train_using_tune pid=52287)\u001b[0m [2026-01-28 14:10:43,795 E 52287 52331] core_worker_process.cc:842: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
      "2026-01-28 14:10:55,515\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.938 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:10:55,518\tWARNING util.py:201 -- The `process_trial_result` operation took 18.941 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:10:55,518\tWARNING util.py:201 -- Processing trial results took 18.941 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:10:55,519\tWARNING util.py:201 -- The `process_trial_result` operation took 18.942 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=52287)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00000_0_batch_size=16,lr=0.0012,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000002)\n",
      "2026-01-28 14:11:14,508\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.919 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:11:14,510\tWARNING util.py:201 -- The `process_trial_result` operation took 18.921 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:11:14,511\tWARNING util.py:201 -- Processing trial results took 18.922 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:11:14,511\tWARNING util.py:201 -- The `process_trial_result` operation took 18.922 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=52287)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00000_0_batch_size=16,lr=0.0012,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000003)\n",
      "2026-01-28 14:11:33,500\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.920 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:11:33,503\tWARNING util.py:201 -- The `process_trial_result` operation took 18.922 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:11:33,503\tWARNING util.py:201 -- Processing trial results took 18.923 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:11:33,504\tWARNING util.py:201 -- The `process_trial_result` operation took 18.924 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=52287)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00000_0_batch_size=16,lr=0.0012,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000004)\n",
      "2026-01-28 14:11:52,509\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.933 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:11:52,511\tWARNING util.py:201 -- The `process_trial_result` operation took 18.935 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:11:52,512\tWARNING util.py:201 -- Processing trial results took 18.935 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:11:52,512\tWARNING util.py:201 -- The `process_trial_result` operation took 18.936 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=52287)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00000_0_batch_size=16,lr=0.0012,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000005)\n",
      "2026-01-28 14:12:11,514\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.930 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:12:11,516\tWARNING util.py:201 -- The `process_trial_result` operation took 18.933 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:12:11,517\tWARNING util.py:201 -- Processing trial results took 18.933 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:12:11,517\tWARNING util.py:201 -- The `process_trial_result` operation took 18.934 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=52287)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00000_0_batch_size=16,lr=0.0012,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000006)\n",
      "2026-01-28 14:12:30,505\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.914 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:12:30,508\tWARNING util.py:201 -- The `process_trial_result` operation took 18.916 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:12:30,508\tWARNING util.py:201 -- Processing trial results took 18.917 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:12:30,509\tWARNING util.py:201 -- The `process_trial_result` operation took 18.918 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=52287)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00000_0_batch_size=16,lr=0.0012,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000007)\n",
      "2026-01-28 14:12:49,503\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.924 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:12:49,505\tWARNING util.py:201 -- The `process_trial_result` operation took 18.926 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:12:49,505\tWARNING util.py:201 -- Processing trial results took 18.927 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:12:49,506\tWARNING util.py:201 -- The `process_trial_result` operation took 18.927 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=52287)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00000_0_batch_size=16,lr=0.0012,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000008)\n",
      "2026-01-28 14:13:08,506\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.931 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:13:08,509\tWARNING util.py:201 -- The `process_trial_result` operation took 18.934 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:13:08,509\tWARNING util.py:201 -- Processing trial results took 18.934 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:13:08,510\tWARNING util.py:201 -- The `process_trial_result` operation took 18.935 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=52287)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00000_0_batch_size=16,lr=0.0012,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000009)\n",
      "2026-01-28 14:13:27,529\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.949 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:13:27,532\tWARNING util.py:201 -- The `process_trial_result` operation took 18.951 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:13:27,532\tWARNING util.py:201 -- Processing trial results took 18.952 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:13:27,533\tWARNING util.py:201 -- The `process_trial_result` operation took 18.952 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=52287)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00000_0_batch_size=16,lr=0.0012,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000010)\n",
      "2026-01-28 14:13:46,549\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.945 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:13:46,551\tWARNING util.py:201 -- The `process_trial_result` operation took 18.947 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:13:46,551\tWARNING util.py:201 -- Processing trial results took 18.948 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:13:46,552\tWARNING util.py:201 -- The `process_trial_result` operation took 18.948 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=52287)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00000_0_batch_size=16,lr=0.0012,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000011)\n",
      "2026-01-28 14:14:05,514\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.891 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:14:05,517\tWARNING util.py:201 -- The `process_trial_result` operation took 18.893 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:14:05,517\tWARNING util.py:201 -- Processing trial results took 18.894 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:14:05,518\tWARNING util.py:201 -- The `process_trial_result` operation took 18.894 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=52287)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00000_0_batch_size=16,lr=0.0012,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000012)\n",
      "2026-01-28 14:14:24,523\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.934 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:14:24,524\tWARNING util.py:201 -- The `process_trial_result` operation took 18.935 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:14:24,526\tWARNING util.py:201 -- Processing trial results took 18.937 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:14:24,526\tWARNING util.py:201 -- The `process_trial_result` operation took 18.937 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=52287)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00000_0_batch_size=16,lr=0.0012,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000013)\n",
      "2026-01-28 14:14:43,510\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.912 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:14:43,512\tWARNING util.py:201 -- The `process_trial_result` operation took 18.915 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:14:43,513\tWARNING util.py:201 -- Processing trial results took 18.916 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:14:43,513\tWARNING util.py:201 -- The `process_trial_result` operation took 18.916 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=52287)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00000_0_batch_size=16,lr=0.0012,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000014)\n",
      "2026-01-28 14:15:02,513\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.928 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:15:02,516\tWARNING util.py:201 -- The `process_trial_result` operation took 18.930 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:15:02,516\tWARNING util.py:201 -- Processing trial results took 18.931 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:15:02,517\tWARNING util.py:201 -- The `process_trial_result` operation took 18.931 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=52287)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00000_0_batch_size=16,lr=0.0012,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000015)\n",
      "2026-01-28 14:15:21,508\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.920 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:15:21,510\tWARNING util.py:201 -- The `process_trial_result` operation took 18.922 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:15:21,511\tWARNING util.py:201 -- Processing trial results took 18.923 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:15:21,511\tWARNING util.py:201 -- The `process_trial_result` operation took 18.923 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=52287)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00000_0_batch_size=16,lr=0.0012,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000016)\n",
      "2026-01-28 14:15:40,564\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.980 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:15:40,565\tWARNING util.py:201 -- The `process_trial_result` operation took 18.982 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:15:40,566\tWARNING util.py:201 -- Processing trial results took 18.982 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:15:40,568\tWARNING util.py:201 -- The `process_trial_result` operation took 18.984 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=52287)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00000_0_batch_size=16,lr=0.0012,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000017)\n",
      "2026-01-28 14:15:59,518\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.880 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:15:59,520\tWARNING util.py:201 -- The `process_trial_result` operation took 18.882 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:15:59,521\tWARNING util.py:201 -- Processing trial results took 18.882 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:15:59,521\tWARNING util.py:201 -- The `process_trial_result` operation took 18.883 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=52287)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00000_0_batch_size=16,lr=0.0012,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000018)\n",
      "2026-01-28 14:16:18,506\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.914 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:16:18,509\tWARNING util.py:201 -- The `process_trial_result` operation took 18.916 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:16:18,509\tWARNING util.py:201 -- Processing trial results took 18.917 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:16:18,510\tWARNING util.py:201 -- The `process_trial_result` operation took 18.918 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=52287)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00000_0_batch_size=16,lr=0.0012,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000019)\n",
      "2026-01-28 14:16:37,506\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.926 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:16:37,508\tWARNING util.py:201 -- The `process_trial_result` operation took 18.929 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:16:37,509\tWARNING util.py:201 -- Processing trial results took 18.929 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:16:37,510\tWARNING util.py:201 -- The `process_trial_result` operation took 18.930 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=52287)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00000_0_batch_size=16,lr=0.0012,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000020)\n",
      "2026-01-28 14:16:56,518\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.937 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:16:56,520\tWARNING util.py:201 -- The `process_trial_result` operation took 18.940 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:16:56,521\tWARNING util.py:201 -- Processing trial results took 18.940 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:16:56,521\tWARNING util.py:201 -- The `process_trial_result` operation took 18.941 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=52287)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00000_0_batch_size=16,lr=0.0012,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000021)\n",
      "2026-01-28 14:17:15,514\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.921 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:17:15,516\tWARNING util.py:201 -- The `process_trial_result` operation took 18.923 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:17:15,516\tWARNING util.py:201 -- Processing trial results took 18.923 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:17:15,517\tWARNING util.py:201 -- The `process_trial_result` operation took 18.924 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=52287)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00000_0_batch_size=16,lr=0.0012,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000022)\n",
      "2026-01-28 14:17:34,508\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.919 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:17:34,510\tWARNING util.py:201 -- The `process_trial_result` operation took 18.921 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:17:34,511\tWARNING util.py:201 -- Processing trial results took 18.922 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:17:34,511\tWARNING util.py:201 -- The `process_trial_result` operation took 18.923 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=52287)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00000_0_batch_size=16,lr=0.0012,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000023)\n",
      "2026-01-28 14:17:53,511\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.929 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:17:53,513\tWARNING util.py:201 -- The `process_trial_result` operation took 18.931 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:17:53,513\tWARNING util.py:201 -- Processing trial results took 18.932 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:17:53,514\tWARNING util.py:201 -- The `process_trial_result` operation took 18.932 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=52287)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00000_0_batch_size=16,lr=0.0012,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000024)\n",
      "2026-01-28 14:18:12,517\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.933 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:18:12,520\tWARNING util.py:201 -- The `process_trial_result` operation took 18.935 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:18:12,521\tWARNING util.py:201 -- Processing trial results took 18.936 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:18:12,521\tWARNING util.py:201 -- The `process_trial_result` operation took 18.937 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=52287)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00000_0_batch_size=16,lr=0.0012,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000025)\n",
      "2026-01-28 14:18:31,514\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.916 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:18:31,516\tWARNING util.py:201 -- The `process_trial_result` operation took 18.918 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:18:31,517\tWARNING util.py:201 -- Processing trial results took 18.918 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:18:31,518\tWARNING util.py:201 -- The `process_trial_result` operation took 18.919 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=52287)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00000_0_batch_size=16,lr=0.0012,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000026)\n",
      "2026-01-28 14:18:50,528\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.940 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:18:50,530\tWARNING util.py:201 -- The `process_trial_result` operation took 18.942 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:18:50,531\tWARNING util.py:201 -- Processing trial results took 18.942 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:18:50,532\tWARNING util.py:201 -- The `process_trial_result` operation took 18.943 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=52287)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00000_0_batch_size=16,lr=0.0012,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000027)\n",
      "2026-01-28 14:19:09,516\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.909 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:19:09,519\tWARNING util.py:201 -- The `process_trial_result` operation took 18.911 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:19:09,519\tWARNING util.py:201 -- Processing trial results took 18.912 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:19:09,520\tWARNING util.py:201 -- The `process_trial_result` operation took 18.913 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=52287)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00000_0_batch_size=16,lr=0.0012,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000028)\n",
      "2026-01-28 14:19:28,514\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.920 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:19:28,516\tWARNING util.py:201 -- The `process_trial_result` operation took 18.922 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:19:28,518\tWARNING util.py:201 -- Processing trial results took 18.923 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:19:28,518\tWARNING util.py:201 -- The `process_trial_result` operation took 18.924 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=52287)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00000_0_batch_size=16,lr=0.0012,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000029)\n",
      "2026-01-28 14:19:47,512\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.915 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:19:47,514\tWARNING util.py:201 -- The `process_trial_result` operation took 18.917 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:19:47,515\tWARNING util.py:201 -- Processing trial results took 18.918 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:19:47,516\tWARNING util.py:201 -- The `process_trial_result` operation took 18.918 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run train_using_tune_0cde6_00000 at: https://dagshub.com/manikantmnnit/diabetes_project.mlflow/#/experiments/2/runs/fb473f7a821546afbc214a06b0a14f26\n",
      "üß™ View experiment at: https://dagshub.com/manikantmnnit/diabetes_project.mlflow/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_using_tune pid=78885)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00001_1_batch_size=64,lr=0.0062,optimizer=adam,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000000)\n",
      "2026-01-28 14:20:26,303\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 15.603 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:20:26,304\tWARNING util.py:201 -- The `process_trial_result` operation took 15.605 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:20:26,305\tWARNING util.py:201 -- Processing trial results took 15.606 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:20:26,306\tWARNING util.py:201 -- The `process_trial_result` operation took 15.606 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=78885)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00001_1_batch_size=64,lr=0.0062,optimizer=adam,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000001)\n",
      "\u001b[36m(train_using_tune pid=78885)\u001b[0m [2026-01-28 14:20:34,112 E 78885 78920] core_worker_process.cc:842: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
      "2026-01-28 14:20:45,305\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.957 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:20:45,307\tWARNING util.py:201 -- The `process_trial_result` operation took 18.960 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:20:45,308\tWARNING util.py:201 -- Processing trial results took 18.960 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:20:45,309\tWARNING util.py:201 -- The `process_trial_result` operation took 18.961 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=78885)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00001_1_batch_size=64,lr=0.0062,optimizer=adam,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000002)\n",
      "2026-01-28 14:21:04,313\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.963 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:21:04,314\tWARNING util.py:201 -- The `process_trial_result` operation took 18.965 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:21:04,316\tWARNING util.py:201 -- Processing trial results took 18.967 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:21:04,317\tWARNING util.py:201 -- The `process_trial_result` operation took 18.968 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=78885)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00001_1_batch_size=64,lr=0.0062,optimizer=adam,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000003)\n",
      "2026-01-28 14:21:23,305\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.947 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:21:23,307\tWARNING util.py:201 -- The `process_trial_result` operation took 18.950 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:21:23,308\tWARNING util.py:201 -- Processing trial results took 18.951 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:21:23,308\tWARNING util.py:201 -- The `process_trial_result` operation took 18.951 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=78885)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00001_1_batch_size=64,lr=0.0062,optimizer=adam,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000004)\n",
      "2026-01-28 14:21:42,304\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.954 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:21:42,306\tWARNING util.py:201 -- The `process_trial_result` operation took 18.957 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:21:42,307\tWARNING util.py:201 -- Processing trial results took 18.957 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:21:42,308\tWARNING util.py:201 -- The `process_trial_result` operation took 18.958 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=78885)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00001_1_batch_size=64,lr=0.0062,optimizer=adam,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000005)\n",
      "2026-01-28 14:22:01,320\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.971 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:22:01,322\tWARNING util.py:201 -- The `process_trial_result` operation took 18.973 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:22:01,323\tWARNING util.py:201 -- Processing trial results took 18.973 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:22:01,323\tWARNING util.py:201 -- The `process_trial_result` operation took 18.974 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=78885)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00001_1_batch_size=64,lr=0.0062,optimizer=adam,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000006)\n",
      "2026-01-28 14:22:20,308\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.943 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:22:20,310\tWARNING util.py:201 -- The `process_trial_result` operation took 18.945 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:22:20,311\tWARNING util.py:201 -- Processing trial results took 18.946 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:22:20,312\tWARNING util.py:201 -- The `process_trial_result` operation took 18.947 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=78885)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00001_1_batch_size=64,lr=0.0062,optimizer=adam,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000007)\n",
      "2026-01-28 14:22:39,320\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.966 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:22:39,322\tWARNING util.py:201 -- The `process_trial_result` operation took 18.969 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:22:39,323\tWARNING util.py:201 -- Processing trial results took 18.969 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:22:39,324\tWARNING util.py:201 -- The `process_trial_result` operation took 18.970 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=78885)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00001_1_batch_size=64,lr=0.0062,optimizer=adam,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000008)\n",
      "2026-01-28 14:22:58,316\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.952 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:22:58,318\tWARNING util.py:201 -- The `process_trial_result` operation took 18.953 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:22:58,319\tWARNING util.py:201 -- Processing trial results took 18.955 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:22:58,321\tWARNING util.py:201 -- The `process_trial_result` operation took 18.956 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=78885)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00001_1_batch_size=64,lr=0.0062,optimizer=adam,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000009)\n",
      "2026-01-28 14:23:17,300\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.935 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:23:17,302\tWARNING util.py:201 -- The `process_trial_result` operation took 18.938 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:23:17,303\tWARNING util.py:201 -- Processing trial results took 18.938 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:23:17,303\tWARNING util.py:201 -- The `process_trial_result` operation took 18.939 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=78885)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00001_1_batch_size=64,lr=0.0062,optimizer=adam,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000010)\n",
      "2026-01-28 14:23:36,307\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.962 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:23:36,309\tWARNING util.py:201 -- The `process_trial_result` operation took 18.963 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:23:36,310\tWARNING util.py:201 -- Processing trial results took 18.964 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:23:36,311\tWARNING util.py:201 -- The `process_trial_result` operation took 18.965 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=78885)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00001_1_batch_size=64,lr=0.0062,optimizer=adam,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000011)\n",
      "2026-01-28 14:23:55,378\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 19.027 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:23:55,379\tWARNING util.py:201 -- The `process_trial_result` operation took 19.029 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:23:55,381\tWARNING util.py:201 -- Processing trial results took 19.030 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:23:55,381\tWARNING util.py:201 -- The `process_trial_result` operation took 19.031 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=78885)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00001_1_batch_size=64,lr=0.0062,optimizer=adam,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000012)\n",
      "2026-01-28 14:24:14,306\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.882 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:24:14,308\tWARNING util.py:201 -- The `process_trial_result` operation took 18.884 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:24:14,309\tWARNING util.py:201 -- Processing trial results took 18.885 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:24:14,310\tWARNING util.py:201 -- The `process_trial_result` operation took 18.886 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=78885)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00001_1_batch_size=64,lr=0.0062,optimizer=adam,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000013)\n",
      "2026-01-28 14:24:33,301\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.950 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:24:33,305\tWARNING util.py:201 -- The `process_trial_result` operation took 18.953 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:24:33,305\tWARNING util.py:201 -- Processing trial results took 18.954 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:24:33,306\tWARNING util.py:201 -- The `process_trial_result` operation took 18.955 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=78885)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00001_1_batch_size=64,lr=0.0062,optimizer=adam,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000014)\n",
      "2026-01-28 14:24:52,305\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.956 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:24:52,307\tWARNING util.py:201 -- The `process_trial_result` operation took 18.959 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:24:52,308\tWARNING util.py:201 -- Processing trial results took 18.959 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:24:52,308\tWARNING util.py:201 -- The `process_trial_result` operation took 18.960 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=78885)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00001_1_batch_size=64,lr=0.0062,optimizer=adam,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000015)\n",
      "2026-01-28 14:25:11,301\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.951 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:25:11,303\tWARNING util.py:201 -- The `process_trial_result` operation took 18.953 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:25:11,303\tWARNING util.py:201 -- Processing trial results took 18.954 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:25:11,304\tWARNING util.py:201 -- The `process_trial_result` operation took 18.954 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=78885)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00001_1_batch_size=64,lr=0.0062,optimizer=adam,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000016)\n",
      "2026-01-28 14:25:30,313\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.967 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:25:30,315\tWARNING util.py:201 -- The `process_trial_result` operation took 18.969 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:25:30,316\tWARNING util.py:201 -- Processing trial results took 18.970 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:25:30,316\tWARNING util.py:201 -- The `process_trial_result` operation took 18.971 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=78885)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00001_1_batch_size=64,lr=0.0062,optimizer=adam,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000017)\n",
      "2026-01-28 14:25:49,299\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.942 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:25:49,302\tWARNING util.py:201 -- The `process_trial_result` operation took 18.945 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:25:49,303\tWARNING util.py:201 -- Processing trial results took 18.946 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:25:49,303\tWARNING util.py:201 -- The `process_trial_result` operation took 18.946 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=78885)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00001_1_batch_size=64,lr=0.0062,optimizer=adam,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000018)\n",
      "2026-01-28 14:26:08,390\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 19.040 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:26:08,392\tWARNING util.py:201 -- The `process_trial_result` operation took 19.042 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:26:08,393\tWARNING util.py:201 -- Processing trial results took 19.043 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:26:08,394\tWARNING util.py:201 -- The `process_trial_result` operation took 19.044 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=78885)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00001_1_batch_size=64,lr=0.0062,optimizer=adam,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000019)\n",
      "2026-01-28 14:26:27,308\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.873 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:26:27,310\tWARNING util.py:201 -- The `process_trial_result` operation took 18.875 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:26:27,312\tWARNING util.py:201 -- Processing trial results took 18.877 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:26:27,312\tWARNING util.py:201 -- The `process_trial_result` operation took 18.877 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=78885)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00001_1_batch_size=64,lr=0.0062,optimizer=adam,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000020)\n",
      "2026-01-28 14:26:46,338\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.986 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:26:46,341\tWARNING util.py:201 -- The `process_trial_result` operation took 18.988 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:26:46,341\tWARNING util.py:201 -- Processing trial results took 18.989 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:26:46,342\tWARNING util.py:201 -- The `process_trial_result` operation took 18.990 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=78885)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00001_1_batch_size=64,lr=0.0062,optimizer=adam,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000021)\n",
      "2026-01-28 14:27:05,329\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.946 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:27:05,331\tWARNING util.py:201 -- The `process_trial_result` operation took 18.948 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:27:05,332\tWARNING util.py:201 -- Processing trial results took 18.950 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:27:05,333\tWARNING util.py:201 -- The `process_trial_result` operation took 18.950 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=78885)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00001_1_batch_size=64,lr=0.0062,optimizer=adam,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000022)\n",
      "2026-01-28 14:27:24,337\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.956 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:27:24,339\tWARNING util.py:201 -- The `process_trial_result` operation took 18.959 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:27:24,340\tWARNING util.py:201 -- Processing trial results took 18.959 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:27:24,340\tWARNING util.py:201 -- The `process_trial_result` operation took 18.960 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=78885)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00001_1_batch_size=64,lr=0.0062,optimizer=adam,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000023)\n",
      "2026-01-28 14:27:43,305\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.924 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:27:43,307\tWARNING util.py:201 -- The `process_trial_result` operation took 18.926 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:27:43,308\tWARNING util.py:201 -- Processing trial results took 18.927 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:27:43,309\tWARNING util.py:201 -- The `process_trial_result` operation took 18.928 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=78885)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00001_1_batch_size=64,lr=0.0062,optimizer=adam,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000024)\n",
      "2026-01-28 14:28:02,317\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.965 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:28:02,319\tWARNING util.py:201 -- The `process_trial_result` operation took 18.967 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:28:02,320\tWARNING util.py:201 -- Processing trial results took 18.968 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:28:02,320\tWARNING util.py:201 -- The `process_trial_result` operation took 18.968 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=78885)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00001_1_batch_size=64,lr=0.0062,optimizer=adam,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000025)\n",
      "2026-01-28 14:28:21,309\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.946 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:28:21,311\tWARNING util.py:201 -- The `process_trial_result` operation took 18.948 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:28:21,312\tWARNING util.py:201 -- Processing trial results took 18.949 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:28:21,313\tWARNING util.py:201 -- The `process_trial_result` operation took 18.950 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=78885)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00001_1_batch_size=64,lr=0.0062,optimizer=adam,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000026)\n",
      "2026-01-28 14:28:40,312\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.958 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:28:40,315\tWARNING util.py:201 -- The `process_trial_result` operation took 18.961 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:28:40,315\tWARNING util.py:201 -- Processing trial results took 18.961 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:28:40,316\tWARNING util.py:201 -- The `process_trial_result` operation took 18.962 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=78885)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00001_1_batch_size=64,lr=0.0062,optimizer=adam,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000027)\n",
      "2026-01-28 14:28:59,326\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.968 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:28:59,328\tWARNING util.py:201 -- The `process_trial_result` operation took 18.970 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:28:59,329\tWARNING util.py:201 -- Processing trial results took 18.971 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:28:59,329\tWARNING util.py:201 -- The `process_trial_result` operation took 18.971 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=78885)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00001_1_batch_size=64,lr=0.0062,optimizer=adam,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000028)\n",
      "2026-01-28 14:29:18,315\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.944 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:29:18,317\tWARNING util.py:201 -- The `process_trial_result` operation took 18.946 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:29:18,318\tWARNING util.py:201 -- Processing trial results took 18.947 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:29:18,319\tWARNING util.py:201 -- The `process_trial_result` operation took 18.947 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=78885)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00001_1_batch_size=64,lr=0.0062,optimizer=adam,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000029)\n",
      "2026-01-28 14:29:37,304\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.943 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:29:37,306\tWARNING util.py:201 -- The `process_trial_result` operation took 18.945 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:29:37,308\tWARNING util.py:201 -- Processing trial results took 18.946 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:29:37,308\tWARNING util.py:201 -- The `process_trial_result` operation took 18.947 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run train_using_tune_0cde6_00001 at: https://dagshub.com/manikantmnnit/diabetes_project.mlflow/#/experiments/2/runs/4d8e0125cff040fabc2446e7e5fdfb39\n",
      "üß™ View experiment at: https://dagshub.com/manikantmnnit/diabetes_project.mlflow/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_using_tune pid=115401)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00002_2_batch_size=32,lr=0.0611,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000000)\n",
      "2026-01-28 14:30:16,343\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 15.321 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:30:16,345\tWARNING util.py:201 -- The `process_trial_result` operation took 15.324 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:30:16,346\tWARNING util.py:201 -- Processing trial results took 15.324 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:30:16,347\tWARNING util.py:201 -- The `process_trial_result` operation took 15.325 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=115401)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00002_2_batch_size=32,lr=0.0611,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000001)\n",
      "\u001b[36m(train_using_tune pid=115401)\u001b[0m [2026-01-28 14:30:24,163 E 115401 115430] core_worker_process.cc:842: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
      "2026-01-28 14:30:35,340\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.942 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:30:35,342\tWARNING util.py:201 -- The `process_trial_result` operation took 18.945 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:30:35,343\tWARNING util.py:201 -- Processing trial results took 18.946 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:30:35,344\tWARNING util.py:201 -- The `process_trial_result` operation took 18.947 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=115401)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00002_2_batch_size=32,lr=0.0611,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000002)\n",
      "2026-01-28 14:30:54,333\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.934 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:30:54,335\tWARNING util.py:201 -- The `process_trial_result` operation took 18.936 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:30:54,336\tWARNING util.py:201 -- Processing trial results took 18.937 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:30:54,337\tWARNING util.py:201 -- The `process_trial_result` operation took 18.938 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=115401)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00002_2_batch_size=32,lr=0.0611,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000003)\n",
      "2026-01-28 14:31:13,337\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.948 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:31:13,339\tWARNING util.py:201 -- The `process_trial_result` operation took 18.951 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:31:13,339\tWARNING util.py:201 -- Processing trial results took 18.951 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:31:13,340\tWARNING util.py:201 -- The `process_trial_result` operation took 18.952 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=115401)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00002_2_batch_size=32,lr=0.0611,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000004)\n",
      "2026-01-28 14:31:32,360\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.969 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:31:32,362\tWARNING util.py:201 -- The `process_trial_result` operation took 18.972 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:31:32,363\tWARNING util.py:201 -- Processing trial results took 18.973 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:31:32,363\tWARNING util.py:201 -- The `process_trial_result` operation took 18.973 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=115401)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00002_2_batch_size=32,lr=0.0611,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000005)\n",
      "2026-01-28 14:31:51,392\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.975 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:31:51,397\tWARNING util.py:201 -- The `process_trial_result` operation took 18.980 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:31:51,398\tWARNING util.py:201 -- Processing trial results took 18.982 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:31:51,399\tWARNING util.py:201 -- The `process_trial_result` operation took 18.983 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=115401)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00002_2_batch_size=32,lr=0.0611,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000006)\n",
      "2026-01-28 14:32:10,347\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.879 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:32:10,349\tWARNING util.py:201 -- The `process_trial_result` operation took 18.881 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:32:10,350\tWARNING util.py:201 -- Processing trial results took 18.882 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:32:10,350\tWARNING util.py:201 -- The `process_trial_result` operation took 18.883 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=115401)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00002_2_batch_size=32,lr=0.0611,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000007)\n",
      "2026-01-28 14:32:29,369\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.966 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:32:29,371\tWARNING util.py:201 -- The `process_trial_result` operation took 18.968 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:32:29,371\tWARNING util.py:201 -- Processing trial results took 18.969 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:32:29,372\tWARNING util.py:201 -- The `process_trial_result` operation took 18.970 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=115401)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00002_2_batch_size=32,lr=0.0611,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000008)\n",
      "2026-01-28 14:32:48,352\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.929 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:32:48,356\tWARNING util.py:201 -- The `process_trial_result` operation took 18.933 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:32:48,357\tWARNING util.py:201 -- Processing trial results took 18.934 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:32:48,358\tWARNING util.py:201 -- The `process_trial_result` operation took 18.934 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=115401)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00002_2_batch_size=32,lr=0.0611,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000009)\n",
      "2026-01-28 14:33:07,343\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.933 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:33:07,345\tWARNING util.py:201 -- The `process_trial_result` operation took 18.936 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:33:07,346\tWARNING util.py:201 -- Processing trial results took 18.936 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:33:07,346\tWARNING util.py:201 -- The `process_trial_result` operation took 18.937 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=115401)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00002_2_batch_size=32,lr=0.0611,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000010)\n",
      "2026-01-28 14:33:26,341\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.943 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:33:26,343\tWARNING util.py:201 -- The `process_trial_result` operation took 18.945 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:33:26,344\tWARNING util.py:201 -- Processing trial results took 18.946 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:33:26,344\tWARNING util.py:201 -- The `process_trial_result` operation took 18.947 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=115401)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00002_2_batch_size=32,lr=0.0611,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000011)\n",
      "2026-01-28 14:33:45,335\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.939 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:33:45,338\tWARNING util.py:201 -- The `process_trial_result` operation took 18.941 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:33:45,339\tWARNING util.py:201 -- Processing trial results took 18.942 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:33:45,339\tWARNING util.py:201 -- The `process_trial_result` operation took 18.943 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=115401)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00002_2_batch_size=32,lr=0.0611,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000012)\n",
      "2026-01-28 14:34:04,347\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.956 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:34:04,349\tWARNING util.py:201 -- The `process_trial_result` operation took 18.958 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:34:04,349\tWARNING util.py:201 -- Processing trial results took 18.959 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:34:04,350\tWARNING util.py:201 -- The `process_trial_result` operation took 18.960 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=115401)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00002_2_batch_size=32,lr=0.0611,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000013)\n",
      "2026-01-28 14:34:23,352\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.948 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:34:23,354\tWARNING util.py:201 -- The `process_trial_result` operation took 18.950 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:34:23,355\tWARNING util.py:201 -- Processing trial results took 18.952 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:34:23,356\tWARNING util.py:201 -- The `process_trial_result` operation took 18.952 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=115401)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00002_2_batch_size=32,lr=0.0611,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000014)\n",
      "2026-01-28 14:34:42,351\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.942 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:34:42,354\tWARNING util.py:201 -- The `process_trial_result` operation took 18.945 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:34:42,355\tWARNING util.py:201 -- Processing trial results took 18.946 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:34:42,355\tWARNING util.py:201 -- The `process_trial_result` operation took 18.946 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=115401)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00002_2_batch_size=32,lr=0.0611,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000015)\n",
      "2026-01-28 14:35:01,351\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.943 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:35:01,354\tWARNING util.py:201 -- The `process_trial_result` operation took 18.945 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:35:01,354\tWARNING util.py:201 -- Processing trial results took 18.946 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:35:01,355\tWARNING util.py:201 -- The `process_trial_result` operation took 18.947 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=115401)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00002_2_batch_size=32,lr=0.0611,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000016)\n",
      "2026-01-28 14:35:20,353\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.943 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:35:20,355\tWARNING util.py:201 -- The `process_trial_result` operation took 18.945 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:35:20,356\tWARNING util.py:201 -- Processing trial results took 18.945 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:35:20,357\tWARNING util.py:201 -- The `process_trial_result` operation took 18.946 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=115401)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00002_2_batch_size=32,lr=0.0611,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000017)\n",
      "2026-01-28 14:35:39,359\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.947 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:35:39,362\tWARNING util.py:201 -- The `process_trial_result` operation took 18.950 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:35:39,362\tWARNING util.py:201 -- Processing trial results took 18.950 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:35:39,363\tWARNING util.py:201 -- The `process_trial_result` operation took 18.951 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=115401)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00002_2_batch_size=32,lr=0.0611,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000018)\n",
      "2026-01-28 14:35:58,351\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.936 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:35:58,353\tWARNING util.py:201 -- The `process_trial_result` operation took 18.938 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:35:58,354\tWARNING util.py:201 -- Processing trial results took 18.938 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:35:58,354\tWARNING util.py:201 -- The `process_trial_result` operation took 18.939 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=115401)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00002_2_batch_size=32,lr=0.0611,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000019)\n",
      "2026-01-28 14:36:17,355\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.949 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:36:17,359\tWARNING util.py:201 -- The `process_trial_result` operation took 18.953 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:36:17,360\tWARNING util.py:201 -- Processing trial results took 18.954 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:36:17,361\tWARNING util.py:201 -- The `process_trial_result` operation took 18.955 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=115401)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00002_2_batch_size=32,lr=0.0611,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000020)\n",
      "2026-01-28 14:36:36,347\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.920 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:36:36,349\tWARNING util.py:201 -- The `process_trial_result` operation took 18.922 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:36:36,350\tWARNING util.py:201 -- Processing trial results took 18.923 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:36:36,351\tWARNING util.py:201 -- The `process_trial_result` operation took 18.924 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=115401)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00002_2_batch_size=32,lr=0.0611,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000021)\n",
      "2026-01-28 14:36:55,459\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 19.056 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:36:55,461\tWARNING util.py:201 -- The `process_trial_result` operation took 19.057 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:36:55,461\tWARNING util.py:201 -- Processing trial results took 19.058 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:36:55,462\tWARNING util.py:201 -- The `process_trial_result` operation took 19.059 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=115401)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00002_2_batch_size=32,lr=0.0611,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000022)\n",
      "2026-01-28 14:37:14,351\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.837 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:37:14,353\tWARNING util.py:201 -- The `process_trial_result` operation took 18.839 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:37:14,354\tWARNING util.py:201 -- Processing trial results took 18.840 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:37:14,355\tWARNING util.py:201 -- The `process_trial_result` operation took 18.841 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=115401)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00002_2_batch_size=32,lr=0.0611,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000023)\n",
      "2026-01-28 14:37:33,348\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.941 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:37:33,350\tWARNING util.py:201 -- The `process_trial_result` operation took 18.943 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:37:33,351\tWARNING util.py:201 -- Processing trial results took 18.944 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:37:33,352\tWARNING util.py:201 -- The `process_trial_result` operation took 18.945 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=115401)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00002_2_batch_size=32,lr=0.0611,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000024)\n",
      "2026-01-28 14:37:52,349\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.945 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:37:52,351\tWARNING util.py:201 -- The `process_trial_result` operation took 18.947 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:37:52,352\tWARNING util.py:201 -- Processing trial results took 18.948 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:37:52,352\tWARNING util.py:201 -- The `process_trial_result` operation took 18.949 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=115401)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00002_2_batch_size=32,lr=0.0611,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000025)\n",
      "2026-01-28 14:38:11,358\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.953 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:38:11,360\tWARNING util.py:201 -- The `process_trial_result` operation took 18.955 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:38:11,362\tWARNING util.py:201 -- Processing trial results took 18.956 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:38:11,362\tWARNING util.py:201 -- The `process_trial_result` operation took 18.957 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=115401)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00002_2_batch_size=32,lr=0.0611,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000026)\n",
      "2026-01-28 14:38:30,357\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.943 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:38:30,359\tWARNING util.py:201 -- The `process_trial_result` operation took 18.945 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:38:30,360\tWARNING util.py:201 -- Processing trial results took 18.946 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:38:30,361\tWARNING util.py:201 -- The `process_trial_result` operation took 18.947 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=115401)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00002_2_batch_size=32,lr=0.0611,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000027)\n",
      "2026-01-28 14:38:49,347\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.934 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:38:49,349\tWARNING util.py:201 -- The `process_trial_result` operation took 18.937 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:38:49,350\tWARNING util.py:201 -- Processing trial results took 18.937 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:38:49,351\tWARNING util.py:201 -- The `process_trial_result` operation took 18.938 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=115401)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00002_2_batch_size=32,lr=0.0611,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000028)\n",
      "2026-01-28 14:39:08,351\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.947 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:39:08,353\tWARNING util.py:201 -- The `process_trial_result` operation took 18.949 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:39:08,354\tWARNING util.py:201 -- Processing trial results took 18.950 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:39:08,354\tWARNING util.py:201 -- The `process_trial_result` operation took 18.950 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=115401)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00002_2_batch_size=32,lr=0.0611,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000029)\n",
      "2026-01-28 14:39:27,339\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.931 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:39:27,341\tWARNING util.py:201 -- The `process_trial_result` operation took 18.934 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:39:27,343\tWARNING util.py:201 -- Processing trial results took 18.935 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:39:27,343\tWARNING util.py:201 -- The `process_trial_result` operation took 18.935 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run train_using_tune_0cde6_00002 at: https://dagshub.com/manikantmnnit/diabetes_project.mlflow/#/experiments/2/runs/bf3a82fa61e54d9989f61d789cf59dfc\n",
      "üß™ View experiment at: https://dagshub.com/manikantmnnit/diabetes_project.mlflow/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_using_tune pid=125514)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00003_3_batch_size=64,lr=0.0154,optimizer=sgd,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000000)\n",
      "2026-01-28 14:40:06,302\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 15.628 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:40:06,304\tWARNING util.py:201 -- The `process_trial_result` operation took 15.630 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:40:06,305\tWARNING util.py:201 -- Processing trial results took 15.631 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:40:06,306\tWARNING util.py:201 -- The `process_trial_result` operation took 15.632 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=125514)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00003_3_batch_size=64,lr=0.0154,optimizer=sgd,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000001)\n",
      "\u001b[36m(train_using_tune pid=125514)\u001b[0m [2026-01-28 14:40:14,169 E 125514 125901] core_worker_process.cc:842: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
      "2026-01-28 14:40:25,317\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.969 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:40:25,320\tWARNING util.py:201 -- The `process_trial_result` operation took 18.973 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:40:25,321\tWARNING util.py:201 -- Processing trial results took 18.974 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:40:25,322\tWARNING util.py:201 -- The `process_trial_result` operation took 18.974 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=125514)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00003_3_batch_size=64,lr=0.0154,optimizer=sgd,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000002)\n",
      "2026-01-28 14:40:44,303\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.940 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:40:44,305\tWARNING util.py:201 -- The `process_trial_result` operation took 18.942 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:40:44,307\tWARNING util.py:201 -- Processing trial results took 18.944 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:40:44,307\tWARNING util.py:201 -- The `process_trial_result` operation took 18.944 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=125514)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00003_3_batch_size=64,lr=0.0154,optimizer=sgd,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000003)\n",
      "2026-01-28 14:41:03,300\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.951 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:41:03,302\tWARNING util.py:201 -- The `process_trial_result` operation took 18.954 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:41:03,303\tWARNING util.py:201 -- Processing trial results took 18.955 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:41:03,303\tWARNING util.py:201 -- The `process_trial_result` operation took 18.955 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=125514)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00003_3_batch_size=64,lr=0.0154,optimizer=sgd,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000004)\n",
      "2026-01-28 14:41:22,305\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.959 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:41:22,307\tWARNING util.py:201 -- The `process_trial_result` operation took 18.962 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:41:22,308\tWARNING util.py:201 -- Processing trial results took 18.963 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:41:22,309\tWARNING util.py:201 -- The `process_trial_result` operation took 18.963 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=125514)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00003_3_batch_size=64,lr=0.0154,optimizer=sgd,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000005)\n",
      "2026-01-28 14:41:41,308\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.955 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:41:41,310\tWARNING util.py:201 -- The `process_trial_result` operation took 18.957 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:41:41,311\tWARNING util.py:201 -- Processing trial results took 18.958 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:41:41,311\tWARNING util.py:201 -- The `process_trial_result` operation took 18.959 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=125514)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00003_3_batch_size=64,lr=0.0154,optimizer=sgd,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000006)\n",
      "2026-01-28 14:42:00,307\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.954 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:42:00,309\tWARNING util.py:201 -- The `process_trial_result` operation took 18.956 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:42:00,310\tWARNING util.py:201 -- Processing trial results took 18.957 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:42:00,310\tWARNING util.py:201 -- The `process_trial_result` operation took 18.958 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=125514)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00003_3_batch_size=64,lr=0.0154,optimizer=sgd,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000007)\n",
      "2026-01-28 14:42:19,318\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.964 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:42:19,320\tWARNING util.py:201 -- The `process_trial_result` operation took 18.967 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:42:19,321\tWARNING util.py:201 -- Processing trial results took 18.968 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:42:19,322\tWARNING util.py:201 -- The `process_trial_result` operation took 18.968 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=125514)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00003_3_batch_size=64,lr=0.0154,optimizer=sgd,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000008)\n",
      "2026-01-28 14:42:38,301\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.939 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:42:38,303\tWARNING util.py:201 -- The `process_trial_result` operation took 18.941 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:42:38,304\tWARNING util.py:201 -- Processing trial results took 18.941 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:42:38,304\tWARNING util.py:201 -- The `process_trial_result` operation took 18.942 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=125514)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00003_3_batch_size=64,lr=0.0154,optimizer=sgd,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000009)\n",
      "2026-01-28 14:42:57,300\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.954 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:42:57,302\tWARNING util.py:201 -- The `process_trial_result` operation took 18.956 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:42:57,303\tWARNING util.py:201 -- Processing trial results took 18.957 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:42:57,303\tWARNING util.py:201 -- The `process_trial_result` operation took 18.957 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=125514)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00003_3_batch_size=64,lr=0.0154,optimizer=sgd,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000010)\n",
      "2026-01-28 14:43:16,303\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.956 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:43:16,305\tWARNING util.py:201 -- The `process_trial_result` operation took 18.958 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:43:16,306\tWARNING util.py:201 -- Processing trial results took 18.959 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:43:16,306\tWARNING util.py:201 -- The `process_trial_result` operation took 18.959 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=125514)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00003_3_batch_size=64,lr=0.0154,optimizer=sgd,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000011)\n",
      "2026-01-28 14:43:35,301\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.954 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:43:35,303\tWARNING util.py:201 -- The `process_trial_result` operation took 18.956 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:43:35,304\tWARNING util.py:201 -- Processing trial results took 18.957 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:43:35,304\tWARNING util.py:201 -- The `process_trial_result` operation took 18.958 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=125514)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00003_3_batch_size=64,lr=0.0154,optimizer=sgd,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000012)\n",
      "2026-01-28 14:43:54,306\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.960 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:43:54,308\tWARNING util.py:201 -- The `process_trial_result` operation took 18.962 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:43:54,308\tWARNING util.py:201 -- Processing trial results took 18.963 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:43:54,309\tWARNING util.py:201 -- The `process_trial_result` operation took 18.964 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=125514)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00003_3_batch_size=64,lr=0.0154,optimizer=sgd,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000013)\n",
      "2026-01-28 14:44:13,303\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.952 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:44:13,305\tWARNING util.py:201 -- The `process_trial_result` operation took 18.954 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:44:13,306\tWARNING util.py:201 -- Processing trial results took 18.955 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:44:13,306\tWARNING util.py:201 -- The `process_trial_result` operation took 18.956 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=125514)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00003_3_batch_size=64,lr=0.0154,optimizer=sgd,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000014)\n",
      "2026-01-28 14:44:32,312\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.958 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:44:32,314\tWARNING util.py:201 -- The `process_trial_result` operation took 18.960 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:44:32,315\tWARNING util.py:201 -- Processing trial results took 18.961 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:44:32,316\tWARNING util.py:201 -- The `process_trial_result` operation took 18.962 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=125514)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00003_3_batch_size=64,lr=0.0154,optimizer=sgd,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000015)\n",
      "2026-01-28 14:44:51,299\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.940 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:44:51,301\tWARNING util.py:201 -- The `process_trial_result` operation took 18.942 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:44:51,302\tWARNING util.py:201 -- Processing trial results took 18.944 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:44:51,302\tWARNING util.py:201 -- The `process_trial_result` operation took 18.944 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=125514)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00003_3_batch_size=64,lr=0.0154,optimizer=sgd,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000016)\n",
      "2026-01-28 14:45:10,311\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.967 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:45:10,313\tWARNING util.py:201 -- The `process_trial_result` operation took 18.969 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:45:10,314\tWARNING util.py:201 -- Processing trial results took 18.971 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:45:10,315\tWARNING util.py:201 -- The `process_trial_result` operation took 18.971 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=125514)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00003_3_batch_size=64,lr=0.0154,optimizer=sgd,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000017)\n",
      "2026-01-28 14:45:29,308\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.951 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:45:29,310\tWARNING util.py:201 -- The `process_trial_result` operation took 18.953 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:45:29,312\tWARNING util.py:201 -- Processing trial results took 18.955 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:45:29,313\tWARNING util.py:201 -- The `process_trial_result` operation took 18.956 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=125514)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00003_3_batch_size=64,lr=0.0154,optimizer=sgd,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000018)\n",
      "2026-01-28 14:45:48,309\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.857 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:45:48,311\tWARNING util.py:201 -- The `process_trial_result` operation took 18.860 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:45:48,312\tWARNING util.py:201 -- Processing trial results took 18.861 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:45:48,313\tWARNING util.py:201 -- The `process_trial_result` operation took 18.862 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=125514)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00003_3_batch_size=64,lr=0.0154,optimizer=sgd,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000019)\n",
      "2026-01-28 14:46:07,318\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.963 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:46:07,320\tWARNING util.py:201 -- The `process_trial_result` operation took 18.966 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:46:07,320\tWARNING util.py:201 -- Processing trial results took 18.966 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:46:07,321\tWARNING util.py:201 -- The `process_trial_result` operation took 18.967 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=125514)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00003_3_batch_size=64,lr=0.0154,optimizer=sgd,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000020)\n",
      "2026-01-28 14:46:26,311\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.950 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:46:26,313\tWARNING util.py:201 -- The `process_trial_result` operation took 18.952 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:46:26,314\tWARNING util.py:201 -- Processing trial results took 18.953 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:46:26,314\tWARNING util.py:201 -- The `process_trial_result` operation took 18.953 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=125514)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00003_3_batch_size=64,lr=0.0154,optimizer=sgd,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000021)\n",
      "2026-01-28 14:46:45,303\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.947 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:46:45,305\tWARNING util.py:201 -- The `process_trial_result` operation took 18.949 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:46:45,306\tWARNING util.py:201 -- Processing trial results took 18.950 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:46:45,306\tWARNING util.py:201 -- The `process_trial_result` operation took 18.951 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=125514)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00003_3_batch_size=64,lr=0.0154,optimizer=sgd,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000022)\n",
      "2026-01-28 14:47:04,301\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.952 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:47:04,304\tWARNING util.py:201 -- The `process_trial_result` operation took 18.955 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:47:04,305\tWARNING util.py:201 -- Processing trial results took 18.956 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:47:04,305\tWARNING util.py:201 -- The `process_trial_result` operation took 18.957 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=125514)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00003_3_batch_size=64,lr=0.0154,optimizer=sgd,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000023)\n",
      "2026-01-28 14:47:23,307\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.960 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:47:23,309\tWARNING util.py:201 -- The `process_trial_result` operation took 18.962 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:47:23,310\tWARNING util.py:201 -- Processing trial results took 18.963 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:47:23,311\tWARNING util.py:201 -- The `process_trial_result` operation took 18.964 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=125514)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00003_3_batch_size=64,lr=0.0154,optimizer=sgd,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000024)\n",
      "2026-01-28 14:47:42,298\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.946 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:47:42,300\tWARNING util.py:201 -- The `process_trial_result` operation took 18.949 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:47:42,301\tWARNING util.py:201 -- Processing trial results took 18.950 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:47:42,302\tWARNING util.py:201 -- The `process_trial_result` operation took 18.950 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=125514)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00003_3_batch_size=64,lr=0.0154,optimizer=sgd,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000025)\n",
      "2026-01-28 14:48:01,297\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.953 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:48:01,299\tWARNING util.py:201 -- The `process_trial_result` operation took 18.955 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:48:01,300\tWARNING util.py:201 -- Processing trial results took 18.957 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:48:01,301\tWARNING util.py:201 -- The `process_trial_result` operation took 18.957 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=125514)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00003_3_batch_size=64,lr=0.0154,optimizer=sgd,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000026)\n",
      "2026-01-28 14:48:20,303\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.959 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:48:20,305\tWARNING util.py:201 -- The `process_trial_result` operation took 18.961 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:48:20,306\tWARNING util.py:201 -- Processing trial results took 18.962 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:48:20,306\tWARNING util.py:201 -- The `process_trial_result` operation took 18.963 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=125514)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00003_3_batch_size=64,lr=0.0154,optimizer=sgd,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000027)\n",
      "2026-01-28 14:48:39,304\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.947 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:48:39,306\tWARNING util.py:201 -- The `process_trial_result` operation took 18.949 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:48:39,307\tWARNING util.py:201 -- Processing trial results took 18.950 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:48:39,307\tWARNING util.py:201 -- The `process_trial_result` operation took 18.950 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=125514)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00003_3_batch_size=64,lr=0.0154,optimizer=sgd,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000028)\n",
      "2026-01-28 14:48:58,298\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.948 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:48:58,300\tWARNING util.py:201 -- The `process_trial_result` operation took 18.951 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:48:58,301\tWARNING util.py:201 -- Processing trial results took 18.951 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:48:58,301\tWARNING util.py:201 -- The `process_trial_result` operation took 18.952 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=125514)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00003_3_batch_size=64,lr=0.0154,optimizer=sgd,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000029)\n",
      "2026-01-28 14:49:17,303\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.960 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:49:17,305\tWARNING util.py:201 -- The `process_trial_result` operation took 18.962 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:49:17,306\tWARNING util.py:201 -- Processing trial results took 18.963 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:49:17,306\tWARNING util.py:201 -- The `process_trial_result` operation took 18.963 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run train_using_tune_0cde6_00003 at: https://dagshub.com/manikantmnnit/diabetes_project.mlflow/#/experiments/2/runs/8d44a62fd5bb4061ab2e4c1f8b0e3d8d\n",
      "üß™ View experiment at: https://dagshub.com/manikantmnnit/diabetes_project.mlflow/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_using_tune pid=143391)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00004_4_batch_size=16,lr=0.0007,optimizer=adam,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000000)\n",
      "2026-01-28 14:49:56,504\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 15.605 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:49:56,506\tWARNING util.py:201 -- The `process_trial_result` operation took 15.607 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:49:56,507\tWARNING util.py:201 -- Processing trial results took 15.608 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:49:56,507\tWARNING util.py:201 -- The `process_trial_result` operation took 15.608 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=143391)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00004_4_batch_size=16,lr=0.0007,optimizer=adam,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000001)\n",
      "\u001b[36m(train_using_tune pid=143391)\u001b[0m [2026-01-28 14:50:04,298 E 143391 143731] core_worker_process.cc:842: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
      "2026-01-28 14:50:15,502\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.917 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:50:15,504\tWARNING util.py:201 -- The `process_trial_result` operation took 18.920 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:50:15,505\tWARNING util.py:201 -- Processing trial results took 18.921 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:50:15,506\tWARNING util.py:201 -- The `process_trial_result` operation took 18.922 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=143391)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00004_4_batch_size=16,lr=0.0007,optimizer=adam,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000002)\n",
      "2026-01-28 14:50:34,497\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.917 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:50:34,499\tWARNING util.py:201 -- The `process_trial_result` operation took 18.920 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:50:34,500\tWARNING util.py:201 -- Processing trial results took 18.920 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:50:34,501\tWARNING util.py:201 -- The `process_trial_result` operation took 18.921 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=143391)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00004_4_batch_size=16,lr=0.0007,optimizer=adam,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000003)\n",
      "2026-01-28 14:50:53,501\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.925 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:50:53,503\tWARNING util.py:201 -- The `process_trial_result` operation took 18.928 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:50:53,504\tWARNING util.py:201 -- Processing trial results took 18.928 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:50:53,504\tWARNING util.py:201 -- The `process_trial_result` operation took 18.929 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run train_using_tune_0cde6_00004 at: https://dagshub.com/manikantmnnit/diabetes_project.mlflow/#/experiments/2/runs/7008fbdc25ba475e9af71207179b21cc\n",
      "üß™ View experiment at: https://dagshub.com/manikantmnnit/diabetes_project.mlflow/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_using_tune pid=147145)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00005_5_batch_size=64,lr=0.0105,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000000)\n",
      "2026-01-28 14:51:32,729\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 15.612 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:51:32,731\tWARNING util.py:201 -- The `process_trial_result` operation took 15.614 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:51:32,732\tWARNING util.py:201 -- Processing trial results took 15.615 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:51:32,732\tWARNING util.py:201 -- The `process_trial_result` operation took 15.615 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=147145)\u001b[0m [2026-01-28 14:51:40,295 E 147145 147168] core_worker_process.cc:842: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run train_using_tune_0cde6_00005 at: https://dagshub.com/manikantmnnit/diabetes_project.mlflow/#/experiments/2/runs/c628b8d3bb194a8aae74c3466015713a\n",
      "üß™ View experiment at: https://dagshub.com/manikantmnnit/diabetes_project.mlflow/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_using_tune pid=148660)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00006_6_batch_size=16,lr=0.0074,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000000)\n",
      "2026-01-28 14:52:11,629\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 15.494 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:52:11,630\tWARNING util.py:201 -- The `process_trial_result` operation took 15.496 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:52:11,631\tWARNING util.py:201 -- Processing trial results took 15.497 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:52:11,632\tWARNING util.py:201 -- The `process_trial_result` operation took 15.498 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=148660)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00006_6_batch_size=16,lr=0.0074,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000001)\n",
      "\u001b[36m(train_using_tune pid=148660)\u001b[0m [2026-01-28 14:52:19,433 E 148660 148945] core_worker_process.cc:842: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
      "2026-01-28 14:52:30,633\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.925 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:52:30,635\tWARNING util.py:201 -- The `process_trial_result` operation took 18.928 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:52:30,636\tWARNING util.py:201 -- Processing trial results took 18.929 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:52:30,637\tWARNING util.py:201 -- The `process_trial_result` operation took 18.930 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=148660)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00006_6_batch_size=16,lr=0.0074,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000002)\n",
      "2026-01-28 14:52:49,624\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.912 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:52:49,626\tWARNING util.py:201 -- The `process_trial_result` operation took 18.915 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:52:49,627\tWARNING util.py:201 -- Processing trial results took 18.915 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:52:49,627\tWARNING util.py:201 -- The `process_trial_result` operation took 18.916 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=148660)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00006_6_batch_size=16,lr=0.0074,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000003)\n",
      "2026-01-28 14:53:08,620\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.915 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:53:08,622\tWARNING util.py:201 -- The `process_trial_result` operation took 18.917 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:53:08,623\tWARNING util.py:201 -- Processing trial results took 18.918 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:53:08,624\tWARNING util.py:201 -- The `process_trial_result` operation took 18.919 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=148660)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00006_6_batch_size=16,lr=0.0074,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000004)\n",
      "2026-01-28 14:53:27,625\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.923 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:53:27,627\tWARNING util.py:201 -- The `process_trial_result` operation took 18.925 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:53:27,628\tWARNING util.py:201 -- Processing trial results took 18.926 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:53:27,629\tWARNING util.py:201 -- The `process_trial_result` operation took 18.926 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=148660)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00006_6_batch_size=16,lr=0.0074,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000005)\n",
      "2026-01-28 14:53:46,621\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.907 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:53:46,623\tWARNING util.py:201 -- The `process_trial_result` operation took 18.909 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:53:46,623\tWARNING util.py:201 -- Processing trial results took 18.909 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:53:46,624\tWARNING util.py:201 -- The `process_trial_result` operation took 18.910 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=148660)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00006_6_batch_size=16,lr=0.0074,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000006)\n",
      "2026-01-28 14:54:05,627\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.928 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:54:05,630\tWARNING util.py:201 -- The `process_trial_result` operation took 18.930 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:54:05,630\tWARNING util.py:201 -- Processing trial results took 18.931 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:54:05,631\tWARNING util.py:201 -- The `process_trial_result` operation took 18.931 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=148660)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00006_6_batch_size=16,lr=0.0074,optimizer=adam,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000007)\n",
      "2026-01-28 14:54:24,642\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 18.933 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:54:24,644\tWARNING util.py:201 -- The `process_trial_result` operation took 18.936 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:54:24,645\tWARNING util.py:201 -- Processing trial results took 18.937 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:54:24,646\tWARNING util.py:201 -- The `process_trial_result` operation took 18.938 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run train_using_tune_0cde6_00006 at: https://dagshub.com/manikantmnnit/diabetes_project.mlflow/#/experiments/2/runs/e306ad32723b432ab3e27ee74ea7a23c\n",
      "üß™ View experiment at: https://dagshub.com/manikantmnnit/diabetes_project.mlflow/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_using_tune pid=159545)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00007_7_batch_size=32,lr=0.0002,optimizer=adam,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000000)\n",
      "2026-01-28 14:55:03,581\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 15.772 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:55:03,583\tWARNING util.py:201 -- The `process_trial_result` operation took 15.775 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:55:03,583\tWARNING util.py:201 -- Processing trial results took 15.775 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:55:03,584\tWARNING util.py:201 -- The `process_trial_result` operation took 15.776 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=159545)\u001b[0m [2026-01-28 14:55:10,792 E 159545 159577] core_worker_process.cc:842: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run train_using_tune_0cde6_00007 at: https://dagshub.com/manikantmnnit/diabetes_project.mlflow/#/experiments/2/runs/9e98675923fc425792d0c24dfc1d46ac\n",
      "üß™ View experiment at: https://dagshub.com/manikantmnnit/diabetes_project.mlflow/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_using_tune pid=162052)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00008_8_batch_size=16,lr=0.0004,optimizer=sgd,weight_decay=0.0001_2026-01-28_14-10-07/checkpoint_000000)\n",
      "2026-01-28 14:55:42,544\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 15.539 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:55:42,546\tWARNING util.py:201 -- The `process_trial_result` operation took 15.541 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:55:42,547\tWARNING util.py:201 -- Processing trial results took 15.542 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:55:42,548\tWARNING util.py:201 -- The `process_trial_result` operation took 15.543 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=162052)\u001b[0m [2026-01-28 14:55:50,116 E 162052 162176] core_worker_process.cc:842: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run train_using_tune_0cde6_00008 at: https://dagshub.com/manikantmnnit/diabetes_project.mlflow/#/experiments/2/runs/b6507f105c6445fc996cbb546ea0d271\n",
      "üß™ View experiment at: https://dagshub.com/manikantmnnit/diabetes_project.mlflow/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_using_tune pid=164396)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_0cde6_00009_9_batch_size=64,lr=0.0004,optimizer=sgd,weight_decay=0.0000_2026-01-28_14-10-07/checkpoint_000000)\n",
      "2026-01-28 14:56:21,580\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 15.851 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:56:21,582\tWARNING util.py:201 -- The `process_trial_result` operation took 15.853 s, which may be a performance bottleneck.\n",
      "2026-01-28 14:56:21,583\tWARNING util.py:201 -- Processing trial results took 15.854 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2026-01-28 14:56:21,584\tWARNING util.py:201 -- The `process_trial_result` operation took 15.855 s, which may be a performance bottleneck.\n",
      "\u001b[36m(train_using_tune pid=164396)\u001b[0m [2026-01-28 14:56:29,384 E 164396 164776] core_worker_process.cc:842: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run train_using_tune_0cde6_00009 at: https://dagshub.com/manikantmnnit/diabetes_project.mlflow/#/experiments/2/runs/cc3c23f32fea49869ef4b51048e099a7\n",
      "üß™ View experiment at: https://dagshub.com/manikantmnnit/diabetes_project.mlflow/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-28 14:56:31,582\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/teamspace/studios/this_studio/ray_results/ray_tune_diabetes' in 0.0130s.\n",
      "2026-01-28 14:56:31,594\tINFO tune.py:1041 -- Total run time: 2783.92 seconds (2783.77 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÜ Best config: {'lr': 0.015413931192308999, 'batch_size': 64, 'optimizer': 'sgd', 'weight_decay': 0.00013154690619449782, 'max_num_epochs': 30, 'num_trials': 10, 'device': 'cuda'}\n",
      "üèÜ Best val_loss: 0.5458181798458099\n",
      "üèÜ Best val_accuracy: 0.7217391304347827\n",
      "‚úÖ Best trial test accuracy: 0.7155\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "    \"batch_size\": tune.choice([16, 32, 64]),\n",
    "    \"optimizer\": tune.choice([\"adam\", \"sgd\"]),\n",
    "    \"weight_decay\": tune.loguniform(1e-6, 1e-2),\n",
    "    \"max_num_epochs\": 30,\n",
    "    \"num_trials\": 10,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "}\n",
    "\n",
    "main(\n",
    "    config=config,\n",
    "    model_cls=LogisticRgressionModel,\n",
    "    df=df,\n",
    "    feature_dim=8,\n",
    "    gpus_per_trial=1 if torch.cuda.is_available() else 0\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ray tune + AIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2026-01-28 15:04:58</td></tr>\n",
       "<tr><td>Running for: </td><td>00:01:22.09        </td></tr>\n",
       "<tr><td>Memory:      </td><td>5.8/15.4 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=5<br>Bracket: Iter 16.000: -0.4886460304260254 | Iter 8.000: -0.5052458345890045 | Iter 4.000: -0.5382557734847069 | Iter 2.000: -0.585990235209465 | Iter 1.000: -0.6749077886343002<br>Logical resource usage: 4.0/4 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">         lr</th><th>optimizer  </th><th style=\"text-align: right;\">  weight_decay</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  train_loss</th><th style=\"text-align: right;\">  train_accuracy</th><th style=\"text-align: right;\">  val_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_using_tune_854db_00000</td><td>TERMINATED</td><td>10.192.11.12:179598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">0.00893382 </td><td>sgd        </td><td style=\"text-align: right;\">   2.20597e-05</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         5.47891</td><td style=\"text-align: right;\">    0.471682</td><td style=\"text-align: right;\">        0.776536</td><td style=\"text-align: right;\">  0.485459</td></tr>\n",
       "<tr><td>train_using_tune_854db_00001</td><td>TERMINATED</td><td>10.192.11.12:180890</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">0.00132497 </td><td>sgd        </td><td style=\"text-align: right;\">   0.00616456 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         3.73397</td><td style=\"text-align: right;\">    0.765672</td><td style=\"text-align: right;\">        0.387337</td><td style=\"text-align: right;\">  0.763798</td></tr>\n",
       "<tr><td>train_using_tune_854db_00002</td><td>TERMINATED</td><td>10.192.11.12:182159</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">0.000265434</td><td>adam       </td><td style=\"text-align: right;\">   0.00290359 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         3.34358</td><td style=\"text-align: right;\">    0.792582</td><td style=\"text-align: right;\">        0.383613</td><td style=\"text-align: right;\">  0.800777</td></tr>\n",
       "<tr><td>train_using_tune_854db_00003</td><td>TERMINATED</td><td>10.192.11.12:183042</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">0.0171474  </td><td>adam       </td><td style=\"text-align: right;\">   0.0015771  </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         3.32032</td><td style=\"text-align: right;\">    0.49755 </td><td style=\"text-align: right;\">        0.763501</td><td style=\"text-align: right;\">  0.540856</td></tr>\n",
       "<tr><td>train_using_tune_854db_00004</td><td>TERMINATED</td><td>10.192.11.12:183216</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">0.00259731 </td><td>adam       </td><td style=\"text-align: right;\">   3.9543e-05 </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         3.32809</td><td style=\"text-align: right;\">    0.676661</td><td style=\"text-align: right;\">        0.579143</td><td style=\"text-align: right;\">  0.648518</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_using_tune pid=179598)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_854db_00000_0_batch_size=32,lr=0.0089,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-03-36/checkpoint_000000)\n",
      "\u001b[36m(train_using_tune pid=179598)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_854db_00000_0_batch_size=32,lr=0.0089,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-03-36/checkpoint_000001)\n",
      "\u001b[36m(train_using_tune pid=179598)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_854db_00000_0_batch_size=32,lr=0.0089,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-03-36/checkpoint_000002)\n",
      "\u001b[36m(train_using_tune pid=179598)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_854db_00000_0_batch_size=32,lr=0.0089,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-03-36/checkpoint_000003)\n",
      "\u001b[36m(train_using_tune pid=179598)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_854db_00000_0_batch_size=32,lr=0.0089,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-03-36/checkpoint_000004)\n",
      "\u001b[36m(train_using_tune pid=179598)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_854db_00000_0_batch_size=32,lr=0.0089,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-03-36/checkpoint_000005)\n",
      "\u001b[36m(train_using_tune pid=179598)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_854db_00000_0_batch_size=32,lr=0.0089,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-03-36/checkpoint_000006)\n",
      "\u001b[36m(train_using_tune pid=179598)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_854db_00000_0_batch_size=32,lr=0.0089,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-03-36/checkpoint_000007)\n",
      "\u001b[36m(train_using_tune pid=179598)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_854db_00000_0_batch_size=32,lr=0.0089,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-03-36/checkpoint_000008)\n",
      "\u001b[36m(train_using_tune pid=179598)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_854db_00000_0_batch_size=32,lr=0.0089,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-03-36/checkpoint_000009)\n",
      "\u001b[36m(train_using_tune pid=179598)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_854db_00000_0_batch_size=32,lr=0.0089,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-03-36/checkpoint_000010)\n",
      "\u001b[36m(train_using_tune pid=179598)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_854db_00000_0_batch_size=32,lr=0.0089,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-03-36/checkpoint_000011)\n",
      "\u001b[36m(train_using_tune pid=179598)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_854db_00000_0_batch_size=32,lr=0.0089,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-03-36/checkpoint_000012)\n",
      "\u001b[36m(train_using_tune pid=179598)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_854db_00000_0_batch_size=32,lr=0.0089,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-03-36/checkpoint_000013)\n",
      "\u001b[36m(train_using_tune pid=179598)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_854db_00000_0_batch_size=32,lr=0.0089,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-03-36/checkpoint_000014)\n",
      "\u001b[36m(train_using_tune pid=179598)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_854db_00000_0_batch_size=32,lr=0.0089,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-03-36/checkpoint_000015)\n",
      "\u001b[36m(train_using_tune pid=179598)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_854db_00000_0_batch_size=32,lr=0.0089,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-03-36/checkpoint_000016)\n",
      "\u001b[36m(train_using_tune pid=179598)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_854db_00000_0_batch_size=32,lr=0.0089,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-03-36/checkpoint_000017)\n",
      "\u001b[36m(train_using_tune pid=179598)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_854db_00000_0_batch_size=32,lr=0.0089,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-03-36/checkpoint_000018)\n",
      "\u001b[36m(train_using_tune pid=179598)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_854db_00000_0_batch_size=32,lr=0.0089,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-03-36/checkpoint_000019)\n",
      "\u001b[36m(train_using_tune pid=179598)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_854db_00000_0_batch_size=32,lr=0.0089,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-03-36/checkpoint_000020)\n",
      "\u001b[36m(train_using_tune pid=179598)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_854db_00000_0_batch_size=32,lr=0.0089,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-03-36/checkpoint_000021)\n",
      "\u001b[36m(train_using_tune pid=179598)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_854db_00000_0_batch_size=32,lr=0.0089,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-03-36/checkpoint_000022)\n",
      "\u001b[36m(train_using_tune pid=179598)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_854db_00000_0_batch_size=32,lr=0.0089,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-03-36/checkpoint_000023)\n",
      "\u001b[36m(train_using_tune pid=179598)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_854db_00000_0_batch_size=32,lr=0.0089,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-03-36/checkpoint_000024)\n",
      "\u001b[36m(train_using_tune pid=179598)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_854db_00000_0_batch_size=32,lr=0.0089,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-03-36/checkpoint_000025)\n",
      "\u001b[36m(train_using_tune pid=179598)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_854db_00000_0_batch_size=32,lr=0.0089,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-03-36/checkpoint_000026)\n",
      "\u001b[36m(train_using_tune pid=179598)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_854db_00000_0_batch_size=32,lr=0.0089,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-03-36/checkpoint_000027)\n",
      "\u001b[36m(train_using_tune pid=179598)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_854db_00000_0_batch_size=32,lr=0.0089,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-03-36/checkpoint_000028)\n",
      "\u001b[36m(train_using_tune pid=179598)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_854db_00000_0_batch_size=32,lr=0.0089,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-03-36/checkpoint_000029)\n",
      "\u001b[36m(train_using_tune pid=180890)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_854db_00001_1_batch_size=32,lr=0.0013,optimizer=sgd,weight_decay=0.0062_2026-01-28_15-03-36/checkpoint_000000)\n",
      "\u001b[36m(train_using_tune pid=182159)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_854db_00002_2_batch_size=64,lr=0.0003,optimizer=adam,weight_decay=0.0029_2026-01-28_15-03-36/checkpoint_000000)\n",
      "\u001b[36m(train_using_tune pid=183042)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_854db_00003_3_batch_size=64,lr=0.0171,optimizer=adam,weight_decay=0.0016_2026-01-28_15-03-36/checkpoint_000001)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_using_tune pid=183216)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_854db_00004_4_batch_size=16,lr=0.0026,optimizer=adam,weight_decay=0.0000_2026-01-28_15-03-36/checkpoint_000000)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "2026-01-28 15:04:58,320\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/teamspace/studios/this_studio/ray_results/ray_tune_diabetes' in 0.0075s.\n",
      "2026-01-28 15:04:58,326\tINFO tune.py:1041 -- Total run time: 82.12 seconds (82.08 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_using_tune pid=183216)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_854db_00004_4_batch_size=16,lr=0.0026,optimizer=adam,weight_decay=0.0000_2026-01-28_15-03-36/checkpoint_000001)\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 1Ô∏è‚É£ Imports\n",
    "# -----------------------------\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune import Checkpoint\n",
    "\n",
    "from aim import Run\n",
    "from aim.pytorch import track_params_dists\n",
    "\n",
    "# -----------------------------\n",
    "# 2Ô∏è‚É£ Dataset & DataModule\n",
    "# -----------------------------\n",
    "url = \"https://raw.githubusercontent.com/npradaschnor/Pima-Indians-Diabetes-Dataset/master/diabetes.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "@dataclass\n",
    "class DiabeticDataset(Dataset):\n",
    "    X: torch.Tensor\n",
    "    y: torch.Tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "class Normalization_dataset(Dataset):\n",
    "    def __init__(self, base_dataset, mean, std):\n",
    "        self.base_dataset = base_dataset\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X, y = self.base_dataset[idx]\n",
    "        X = (X - self.mean) / (self.std + 1e-8)\n",
    "        return X, y\n",
    "\n",
    "class DiabeticDataModule:\n",
    "    \"\"\"Minimal Lightning-style datamodule\"\"\"\n",
    "    def __init__(self, df, batch_size=32, train_ratio=0.7, val_ratio=0.15, seed=42):\n",
    "        self.df = df\n",
    "        self.batch_size = batch_size\n",
    "        self.train_ratio = train_ratio\n",
    "        self.val_ratio = val_ratio\n",
    "        self.seed = seed\n",
    "\n",
    "    def setup(self):\n",
    "        X = torch.tensor(self.df.drop(columns=\"Outcome\").values, dtype=torch.float32)\n",
    "        y = torch.tensor(self.df[\"Outcome\"].values, dtype=torch.long)\n",
    "        dataset = DiabeticDataset(X, y)\n",
    "\n",
    "        n_total = len(dataset)\n",
    "        n_train = int(self.train_ratio * n_total)\n",
    "        n_val   = int(self.val_ratio * n_total)\n",
    "        n_test  = n_total - n_train - n_val\n",
    "\n",
    "        generator = torch.Generator().manual_seed(self.seed)\n",
    "        self.train_ds, self.val_ds, self.test_ds = random_split(\n",
    "            dataset, [n_train, n_val, n_test], generator=generator\n",
    "        )\n",
    "\n",
    "    def normalize_datasets(self):\n",
    "        X_all = torch.cat([X for X, _ in DataLoader(self.train_ds, batch_size=self.batch_size)], dim=0)\n",
    "        mean = X_all.mean(dim=0)\n",
    "        std  = X_all.std(dim=0)\n",
    "\n",
    "        self.train_ds = Normalization_dataset(self.train_ds, mean, std)\n",
    "        self.val_ds   = Normalization_dataset(self.val_ds, mean, std)\n",
    "        self.test_ds  = Normalization_dataset(self.test_ds, mean, std)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_ds, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_ds, batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_ds, batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "# -----------------------------\n",
    "# 3Ô∏è‚É£ Model\n",
    "# -----------------------------\n",
    "class LogisticRgressionModel(nn.Module):\n",
    "    def __init__(self, feature_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(feature_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# -----------------------------\n",
    "# 4Ô∏è‚É£ Ray Tune training function with Aim logging\n",
    "# -----------------------------\n",
    "def train_using_tune(config, model_cls, feature_dim, df):\n",
    "    # 1Ô∏è‚É£ Aim run per trial\n",
    "    run = Run(experiment=\"diabetes_ray_tune\")\n",
    "    run[\"lr\"] = config[\"lr\"]\n",
    "    run[\"batch_size\"] = int(config[\"batch_size\"])\n",
    "    run[\"optimizer\"] = config[\"optimizer\"]\n",
    "    run[\"weight_decay\"] = config[\"weight_decay\"]\n",
    "    run[\"max_num_epochs\"] = config[\"max_num_epochs\"]\n",
    "\n",
    "    device = config[\"device\"]\n",
    "    batch_size = int(config[\"batch_size\"])\n",
    "    lr = config[\"lr\"]\n",
    "\n",
    "    # 2Ô∏è‚É£ DataModule\n",
    "    dm = DiabeticDataModule(df=df, batch_size=batch_size)\n",
    "    dm.setup()\n",
    "    dm.normalize_datasets()\n",
    "\n",
    "    train_loader = dm.train_dataloader()\n",
    "    valid_loader = dm.val_dataloader()\n",
    "\n",
    "    # 3Ô∏è‚É£ Model\n",
    "    model = model_cls(feature_dim).to(device)\n",
    "\n",
    "    # 4Ô∏è‚É£ Optimizer\n",
    "    if config[\"optimizer\"] == \"adam\":\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=config[\"weight_decay\"])\n",
    "    else:\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=config[\"weight_decay\"])\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # 5Ô∏è‚É£ Restore checkpoint if exists\n",
    "    checkpoint = tune.get_checkpoint()\n",
    "    if checkpoint:\n",
    "        with checkpoint.as_directory() as ckpt_dir:\n",
    "            model_state, optimizer_state = torch.load(os.path.join(ckpt_dir, \"checkpoint.pt\"), map_location=device)\n",
    "            model.load_state_dict(model_state)\n",
    "            optimizer.load_state_dict(optimizer_state)\n",
    "\n",
    "    # 6Ô∏è‚É£ Training loop\n",
    "    for epoch in range(config[\"max_num_epochs\"]):\n",
    "        model.train()\n",
    "        total_train_loss, correct_train, total_train = 0, 0, 0\n",
    "\n",
    "        for X, y in train_loader:\n",
    "            X, y = X.to(device), y.float().unsqueeze(1).to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(X)\n",
    "            loss = criterion(logits, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "            preds = (torch.sigmoid(logits) > 0.5).long()\n",
    "            correct_train += (preds == y.long()).sum().item()\n",
    "            total_train += y.size(0)\n",
    "\n",
    "        train_loss = total_train_loss / len(train_loader)\n",
    "        train_acc  = correct_train / total_train\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        total_val_loss, correct_val, total_val = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for X, y in valid_loader:\n",
    "                X, y = X.to(device), y.float().unsqueeze(1).to(device)\n",
    "                logits = model(X)\n",
    "                loss = criterion(logits, y)\n",
    "                total_val_loss += loss.item()\n",
    "                preds = (torch.sigmoid(logits) > 0.5).long()\n",
    "                correct_val += (preds == y.long()).sum().item()\n",
    "                total_val += y.size(0)\n",
    "\n",
    "        val_loss = total_val_loss / len(valid_loader)\n",
    "        val_acc  = correct_val / total_val\n",
    "\n",
    "        # Aim logging\n",
    "        run.track(train_loss, name=\"train_loss\", step=epoch)\n",
    "        run.track(train_acc,  name=\"train_accuracy\", step=epoch)\n",
    "        run.track(val_loss,   name=\"val_loss\", step=epoch)\n",
    "        run.track(val_acc,    name=\"val_accuracy\", step=epoch)\n",
    "        track_params_dists(model, run=run)\n",
    "\n",
    "        # Ray Tune checkpoint\n",
    "        with tempfile.TemporaryDirectory() as temp_ckpt_dir:\n",
    "            ckpt_path = os.path.join(temp_ckpt_dir, \"checkpoint.pt\")\n",
    "            torch.save((model.state_dict(), optimizer.state_dict()), ckpt_path)\n",
    "            checkpoint = tune.Checkpoint.from_directory(temp_ckpt_dir)\n",
    "            tune.report(\n",
    "                        {\n",
    "                            \"train_loss\": train_loss,\n",
    "                            \"train_accuracy\": train_acc,\n",
    "                            \"val_loss\": val_loss,\n",
    "                            \"val_accuracy\": val_acc\n",
    "                        },\n",
    "                        checkpoint=checkpoint\n",
    "                    )\n",
    "\n",
    "\n",
    "    run.close()\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 5Ô∏è‚É£ Set config & run tuner\n",
    "# -----------------------------\n",
    "config = {\n",
    "    \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "    \"batch_size\": tune.choice([16, 32, 64]),\n",
    "    \"optimizer\": tune.choice([\"adam\", \"sgd\"]),\n",
    "    \"weight_decay\": tune.loguniform(1e-5, 1e-2),\n",
    "    \"max_num_epochs\": 30,\n",
    "    \"num_trials\": 5,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "}\n",
    "\n",
    "# Assign model & input dimension\n",
    "model_cls = LogisticRgressionModel\n",
    "feature_dim = 8\n",
    "\n",
    "# Determine GPUs for Ray\n",
    "gpus_per_trial = 1 if torch.cuda.is_available() else 0\n",
    "\n",
    "# Scheduler\n",
    "scheduler = ASHAScheduler(\n",
    "    time_attr=\"training_iteration\",\n",
    "    max_t=config[\"max_num_epochs\"],\n",
    "    grace_period=1,\n",
    "    reduction_factor=2\n",
    ")\n",
    "\n",
    "# CLIReporter for console\n",
    "reporter = CLIReporter(metric_columns=[\"train_loss\",\"val_loss\",\"train_accuracy\",\"val_accuracy\"])\n",
    "\n",
    "# Run the tuner\n",
    "tuner = tune.Tuner(\n",
    "    tune.with_resources(\n",
    "        tune.with_parameters(train_using_tune,\n",
    "                             model_cls=model_cls,\n",
    "                             feature_dim=feature_dim,\n",
    "                             df=df),\n",
    "        resources={\"cpu\": 4, \"gpu\": gpus_per_trial}\n",
    "    ),\n",
    "    tune_config=tune.TuneConfig(\n",
    "        metric=\"val_loss\",\n",
    "        mode=\"min\",\n",
    "        scheduler=scheduler,\n",
    "        num_samples=config[\"num_trials\"],\n",
    "    ),\n",
    "    run_config=tune.RunConfig(\n",
    "        name=\"ray_tune_diabetes\",\n",
    "    ),\n",
    "    param_space=config,\n",
    ")\n",
    "results = tuner.fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Result(\n",
       "  metrics={'train_loss': 0.47168173509485584, 'train_accuracy': 0.776536312849162, 'val_loss': 0.4854586720466614, 'val_accuracy': 0.7391304347826086},\n",
       "  path='/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_854db_00000_0_batch_size=32,lr=0.0089,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-03-36',\n",
       "  filesystem='local',\n",
       "  checkpoint=Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_854db_00000_0_batch_size=32,lr=0.0089,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-03-36/checkpoint_000029)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_result = tuner.get_results().get_best_result(\"val_loss\", \"min\")\n",
    "best_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResultGrid<[\n",
       "  Result(\n",
       "    metrics={'train_loss': 0.4783506831702064, 'train_accuracy': 0.776536312849162, 'val_loss': 0.5121450014412403, 'val_accuracy': 0.7478260869565218},\n",
       "    path='/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_c5dfd_00000_0_batch_size=16,lr=0.0091,optimizer=sgd,weight_decay=0.0011_2026-01-26_16-47-59',\n",
       "    filesystem='local',\n",
       "    checkpoint=Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_c5dfd_00000_0_batch_size=16,lr=0.0091,optimizer=sgd,weight_decay=0.0011_2026-01-26_16-47-59/checkpoint_000029)\n",
       "  ),\n",
       "  Result(\n",
       "    metrics={'train_loss': 0.6856310402645784, 'train_accuracy': 0.5716945996275605, 'val_loss': 0.7359677702188492, 'val_accuracy': 0.5565217391304348},\n",
       "    path='/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_c5dfd_00001_1_batch_size=32,lr=0.0018,optimizer=sgd,weight_decay=0.0000_2026-01-26_16-47-59',\n",
       "    filesystem='local',\n",
       "    checkpoint=Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_c5dfd_00001_1_batch_size=32,lr=0.0018,optimizer=sgd,weight_decay=0.0000_2026-01-26_16-47-59/checkpoint_000000)\n",
       "  ),\n",
       "  Result(\n",
       "    metrics={'train_loss': 0.470757438076867, 'train_accuracy': 0.7783985102420856, 'val_loss': 0.4866490364074707, 'val_accuracy': 0.7478260869565218},\n",
       "    path='/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_c5dfd_00002_2_batch_size=64,lr=0.0257,optimizer=adam,weight_decay=0.0006_2026-01-26_16-47-59',\n",
       "    filesystem='local',\n",
       "    checkpoint=Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_c5dfd_00002_2_batch_size=64,lr=0.0257,optimizer=adam,weight_decay=0.0006_2026-01-26_16-47-59/checkpoint_000029)\n",
       "  ),\n",
       "  Result(\n",
       "    metrics={'train_loss': 0.7723057585604051, 'train_accuracy': 0.49906890130353815, 'val_loss': 0.7619470208883286, 'val_accuracy': 0.4},\n",
       "    path='/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_c5dfd_00003_3_batch_size=16,lr=0.0002,optimizer=adam,weight_decay=0.0001_2026-01-26_16-47-59',\n",
       "    filesystem='local',\n",
       "    checkpoint=Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_c5dfd_00003_3_batch_size=16,lr=0.0002,optimizer=adam,weight_decay=0.0001_2026-01-26_16-47-59/checkpoint_000000)\n",
       "  ),\n",
       "  Result(\n",
       "    metrics={'train_loss': 0.7126285188338336, 'train_accuracy': 0.5325884543761639, 'val_loss': 0.7024298161268234, 'val_accuracy': 0.5652173913043478},\n",
       "    path='/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_c5dfd_00004_4_batch_size=32,lr=0.0010,optimizer=sgd,weight_decay=0.0026_2026-01-26_16-47-59',\n",
       "    filesystem='local',\n",
       "    checkpoint=Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_c5dfd_00004_4_batch_size=32,lr=0.0010,optimizer=sgd,weight_decay=0.0026_2026-01-26_16-47-59/checkpoint_000000)\n",
       "  )\n",
       "]>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_using_tune pid=187326)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_15-09-37/train_using_tune_5cb3d_00000_0_batch_size=64,lr=0.0173,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-09-37/checkpoint_000000)\n",
      "\u001b[36m(train_using_tune pid=187326)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_15-09-37/train_using_tune_5cb3d_00000_0_batch_size=64,lr=0.0173,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-09-37/checkpoint_000001)\n",
      "\u001b[36m(train_using_tune pid=187326)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_15-09-37/train_using_tune_5cb3d_00000_0_batch_size=64,lr=0.0173,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-09-37/checkpoint_000002)\n",
      "\u001b[36m(train_using_tune pid=187326)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_15-09-37/train_using_tune_5cb3d_00000_0_batch_size=64,lr=0.0173,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-09-37/checkpoint_000003)\n",
      "\u001b[36m(train_using_tune pid=187326)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_15-09-37/train_using_tune_5cb3d_00000_0_batch_size=64,lr=0.0173,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-09-37/checkpoint_000004)\n",
      "\u001b[36m(train_using_tune pid=187326)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_15-09-37/train_using_tune_5cb3d_00000_0_batch_size=64,lr=0.0173,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-09-37/checkpoint_000005)\n",
      "\u001b[36m(train_using_tune pid=187326)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_15-09-37/train_using_tune_5cb3d_00000_0_batch_size=64,lr=0.0173,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-09-37/checkpoint_000006)\n",
      "\u001b[36m(train_using_tune pid=187326)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_15-09-37/train_using_tune_5cb3d_00000_0_batch_size=64,lr=0.0173,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-09-37/checkpoint_000007)\n",
      "\u001b[36m(train_using_tune pid=187326)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_15-09-37/train_using_tune_5cb3d_00000_0_batch_size=64,lr=0.0173,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-09-37/checkpoint_000008)\n",
      "\u001b[36m(train_using_tune pid=187326)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_15-09-37/train_using_tune_5cb3d_00000_0_batch_size=64,lr=0.0173,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-09-37/checkpoint_000009)\n",
      "\u001b[36m(train_using_tune pid=187326)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_15-09-37/train_using_tune_5cb3d_00000_0_batch_size=64,lr=0.0173,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-09-37/checkpoint_000010)\n",
      "\u001b[36m(train_using_tune pid=187326)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_15-09-37/train_using_tune_5cb3d_00000_0_batch_size=64,lr=0.0173,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-09-37/checkpoint_000011)\n",
      "\u001b[36m(train_using_tune pid=187326)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_15-09-37/train_using_tune_5cb3d_00000_0_batch_size=64,lr=0.0173,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-09-37/checkpoint_000012)\n",
      "\u001b[36m(train_using_tune pid=187326)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_15-09-37/train_using_tune_5cb3d_00000_0_batch_size=64,lr=0.0173,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-09-37/checkpoint_000013)\n",
      "\u001b[36m(train_using_tune pid=187326)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_15-09-37/train_using_tune_5cb3d_00000_0_batch_size=64,lr=0.0173,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-09-37/checkpoint_000014)\n",
      "\u001b[36m(train_using_tune pid=187326)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_15-09-37/train_using_tune_5cb3d_00000_0_batch_size=64,lr=0.0173,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-09-37/checkpoint_000015)\n",
      "\u001b[36m(train_using_tune pid=187326)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_15-09-37/train_using_tune_5cb3d_00000_0_batch_size=64,lr=0.0173,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-09-37/checkpoint_000016)\n",
      "\u001b[36m(train_using_tune pid=187326)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_15-09-37/train_using_tune_5cb3d_00000_0_batch_size=64,lr=0.0173,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-09-37/checkpoint_000017)\n",
      "\u001b[36m(train_using_tune pid=187326)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_15-09-37/train_using_tune_5cb3d_00000_0_batch_size=64,lr=0.0173,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-09-37/checkpoint_000018)\n",
      "\u001b[36m(train_using_tune pid=187326)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_15-09-37/train_using_tune_5cb3d_00000_0_batch_size=64,lr=0.0173,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-09-37/checkpoint_000019)\n",
      "\u001b[36m(train_using_tune pid=187326)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_15-09-37/train_using_tune_5cb3d_00000_0_batch_size=64,lr=0.0173,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-09-37/checkpoint_000020)\n",
      "\u001b[36m(train_using_tune pid=187326)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_15-09-37/train_using_tune_5cb3d_00000_0_batch_size=64,lr=0.0173,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-09-37/checkpoint_000021)\n",
      "\u001b[36m(train_using_tune pid=187326)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_15-09-37/train_using_tune_5cb3d_00000_0_batch_size=64,lr=0.0173,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-09-37/checkpoint_000022)\n",
      "\u001b[36m(train_using_tune pid=187326)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_15-09-37/train_using_tune_5cb3d_00000_0_batch_size=64,lr=0.0173,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-09-37/checkpoint_000023)\n",
      "\u001b[36m(train_using_tune pid=187326)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_15-09-37/train_using_tune_5cb3d_00000_0_batch_size=64,lr=0.0173,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-09-37/checkpoint_000024)\n",
      "\u001b[36m(train_using_tune pid=187326)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_15-09-37/train_using_tune_5cb3d_00000_0_batch_size=64,lr=0.0173,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-09-37/checkpoint_000025)\n",
      "\u001b[36m(train_using_tune pid=187326)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_15-09-37/train_using_tune_5cb3d_00000_0_batch_size=64,lr=0.0173,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-09-37/checkpoint_000026)\n",
      "\u001b[36m(train_using_tune pid=187326)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_15-09-37/train_using_tune_5cb3d_00000_0_batch_size=64,lr=0.0173,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-09-37/checkpoint_000027)\n",
      "\u001b[36m(train_using_tune pid=187326)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_15-09-37/train_using_tune_5cb3d_00000_0_batch_size=64,lr=0.0173,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-09-37/checkpoint_000028)\n",
      "\u001b[36m(train_using_tune pid=187326)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_15-09-37/train_using_tune_5cb3d_00000_0_batch_size=64,lr=0.0173,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-09-37/checkpoint_000029)\n",
      "\u001b[36m(train_using_tune pid=188209)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_15-09-37/train_using_tune_5cb3d_00001_1_batch_size=32,lr=0.0440,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-09-37/checkpoint_000002)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(train_using_tune pid=188726)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_15-09-37/train_using_tune_5cb3d_00002_2_batch_size=64,lr=0.0002,optimizer=adam,weight_decay=0.0007_2026-01-28_15-09-37/checkpoint_000000)\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[36m(train_using_tune pid=188899)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_15-09-37/train_using_tune_5cb3d_00003_3_batch_size=64,lr=0.0048,optimizer=sgd,weight_decay=0.0095_2026-01-28_15-09-37/checkpoint_000000)\n",
      "2026-01-28 15:10:46,321\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_15-09-37' in 0.0058s.\n",
      "2026-01-28 15:10:46,328\tINFO tune.py:1041 -- Total run time: 68.74 seconds (68.71 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÜ Best trial config: {'lr': 0.017300500849656873, 'batch_size': 64, 'optimizer': 'sgd', 'weight_decay': 2.4802550795418668e-05, 'max_num_epochs': 30, 'num_trials': 5, 'device': 'cuda'}\n",
      "üèÜ Best val_loss: 0.48939231038093567\n",
      "üèÜ Best val_accuracy: 0.7391304347826086\n",
      "‚úÖ Best trial test set accuracy: 0.8017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_using_tune pid=189072)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-28_15-09-37/train_using_tune_5cb3d_00004_4_batch_size=32,lr=0.0039,optimizer=adam,weight_decay=0.0000_2026-01-28_15-09-37/checkpoint_000000)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import tempfile\n",
    "import os\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from aim import Run\n",
    "from aim.pytorch import track_params_dists\n",
    "\n",
    "# ------------------ Training function for Ray Tune ------------------\n",
    "def train_using_tune(config, model_cls, feature_dim, df):\n",
    "    \"\"\"\n",
    "    Train a single Ray Tune trial and log metrics to Aim.\n",
    "    \"\"\"\n",
    "    # ----- Setup Aim run (1 per trial) -----\n",
    "    run = Run(experiment=\"diabetes_ray_tune\")\n",
    "\n",
    "    # Log hyperparameters\n",
    "    run[\"lr\"] = config[\"lr\"]\n",
    "    run[\"batch_size\"] = int(config[\"batch_size\"])\n",
    "    run[\"optimizer\"] = config[\"optimizer\"]\n",
    "    run[\"weight_decay\"] = config[\"weight_decay\"]\n",
    "    run[\"max_num_epochs\"] = config[\"max_num_epochs\"]\n",
    "\n",
    "    device = config[\"device\"]\n",
    "    batch_size = int(config[\"batch_size\"])\n",
    "    lr = config[\"lr\"]\n",
    "\n",
    "    # ----- Prepare DataModule -----\n",
    "    dm = DiabeticDataModule(df=df, batch_size=batch_size)\n",
    "    dm.setup()\n",
    "    dm.normalize_datasets()\n",
    "\n",
    "    train_loader = dm.train_dataloader()\n",
    "    val_loader = dm.val_dataloader()\n",
    "    test_loader = dm.test_dataloader()\n",
    "\n",
    "    # ----- Build model -----\n",
    "    model = model_cls(feature_dim).to(device)\n",
    "\n",
    "    # ----- Optimizer -----\n",
    "    if config[\"optimizer\"].lower() == \"adam\":\n",
    "        optimizer = torch.optim.Adam(\n",
    "            model.parameters(), lr=lr, weight_decay=config[\"weight_decay\"]\n",
    "        )\n",
    "    else:\n",
    "        optimizer = torch.optim.SGD(\n",
    "            model.parameters(), lr=lr, momentum=0.9, weight_decay=config[\"weight_decay\"]\n",
    "        )\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # ----- Restore checkpoint if exists -----\n",
    "    checkpoint = tune.get_checkpoint()\n",
    "    if checkpoint:\n",
    "        with checkpoint.as_directory() as ckpt_dir:\n",
    "            model_state, optimizer_state = torch.load(\n",
    "                os.path.join(ckpt_dir, \"checkpoint.pt\"), map_location=device\n",
    "            )\n",
    "            model.load_state_dict(model_state)\n",
    "            optimizer.load_state_dict(optimizer_state)\n",
    "\n",
    "    # ----- Training Loop -----\n",
    "    for epoch in range(config[\"max_num_epochs\"]):\n",
    "        # ------- TRAIN -------\n",
    "        model.train()\n",
    "        total_train_loss, correct_train, total_train = 0.0, 0, 0\n",
    "\n",
    "        for X, y in train_loader:\n",
    "            X, y = X.to(device), y.float().unsqueeze(1).to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(X)\n",
    "            loss = criterion(logits, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "            preds = (torch.sigmoid(logits) > 0.5).long()\n",
    "            correct_train += (preds == y.long()).sum().item()\n",
    "            total_train += y.size(0)\n",
    "\n",
    "        train_loss = total_train_loss / len(train_loader)\n",
    "        train_acc = correct_train / total_train\n",
    "\n",
    "        # ------- VALIDATION -------\n",
    "        model.eval()\n",
    "        total_val_loss, correct_val, total_val = 0.0, 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X, y in val_loader:\n",
    "                X, y = X.to(device), y.float().unsqueeze(1).to(device)\n",
    "\n",
    "                logits = model(X)\n",
    "                loss = criterion(logits, y)\n",
    "                total_val_loss += loss.item()\n",
    "\n",
    "                preds = (torch.sigmoid(logits) > 0.5).long()\n",
    "                correct_val += (preds == y.long()).sum().item()\n",
    "                total_val += y.size(0)\n",
    "\n",
    "        val_loss = total_val_loss / len(val_loader)\n",
    "        val_acc = correct_val / total_val\n",
    "\n",
    "        # ------- Aim logging -------\n",
    "        run.track(train_loss, name=\"train_loss\", step=epoch)\n",
    "        run.track(train_acc, name=\"train_accuracy\", step=epoch)\n",
    "        run.track(val_loss, name=\"val_loss\", step=epoch)\n",
    "        run.track(val_acc, name=\"val_accuracy\", step=epoch)\n",
    "\n",
    "        # Track parameter distributions (weights & biases)\n",
    "        track_params_dists(model, run=run)\n",
    "\n",
    "        # ------- Save checkpoint & report to Ray Tune -------\n",
    "        with tempfile.TemporaryDirectory() as tmp_dir:\n",
    "            ckpt_path = os.path.join(tmp_dir, \"checkpoint.pt\")\n",
    "            torch.save((model.state_dict(), optimizer.state_dict()), ckpt_path)\n",
    "            tune_checkpoint = tune.Checkpoint.from_directory(tmp_dir)\n",
    "            tune.report(\n",
    "                metrics={\n",
    "                    \"train_loss\": train_loss,\n",
    "                    \"train_accuracy\": train_acc,\n",
    "                    \"val_loss\": val_loss,\n",
    "                    \"val_accuracy\": val_acc\n",
    "                },\n",
    "                checkpoint=tune_checkpoint\n",
    "            )\n",
    "\n",
    "    run.close()  # üîπ important\n",
    "\n",
    "# ------------------ Test best trial ------------------\n",
    "def test_best_model(best_result, model_cls, feature_dim, df):\n",
    "    device = best_result.config[\"device\"]\n",
    "    model = model_cls(feature_dim).to(device)\n",
    "\n",
    "    checkpoint = best_result.checkpoint\n",
    "    with checkpoint.as_directory() as ckpt_dir:\n",
    "        model_state, _ = torch.load(os.path.join(ckpt_dir, \"checkpoint.pt\"), map_location=device)\n",
    "    model.load_state_dict(model_state)\n",
    "    model.eval()\n",
    "\n",
    "    # Prepare test loader\n",
    "    dm = DiabeticDataModule(df=df, batch_size=best_result.config[\"batch_size\"])\n",
    "    dm.setup()\n",
    "    dm.normalize_datasets()\n",
    "    test_loader = dm.test_dataloader()\n",
    "\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_loader:\n",
    "            X, y = X.to(device), y.float().unsqueeze(1).to(device)\n",
    "            preds = (torch.sigmoid(model(X)) > 0.5).long()\n",
    "            correct += (preds == y.long()).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "    print(f\"‚úÖ Best trial test set accuracy: {correct / total:.4f}\")\n",
    "\n",
    "# ------------------ Main Ray Tune + Aim ------------------\n",
    "def run_ray_tune_aim(config, model_cls, feature_dim, df, gpus_per_trial=1):\n",
    "    scheduler = ASHAScheduler(\n",
    "        time_attr=\"training_iteration\",\n",
    "        max_t=config[\"max_num_epochs\"],\n",
    "        grace_period=1,\n",
    "        reduction_factor=2\n",
    "    )\n",
    "\n",
    "    tuner = tune.Tuner(\n",
    "        tune.with_resources(\n",
    "            tune.with_parameters(\n",
    "                train_using_tune,\n",
    "                model_cls=model_cls,\n",
    "                feature_dim=feature_dim,\n",
    "                df=df\n",
    "            ),\n",
    "            resources={\"cpu\": 4, \"gpu\": gpus_per_trial}\n",
    "        ),\n",
    "        tune_config=tune.TuneConfig(\n",
    "            metric=\"val_loss\",\n",
    "            mode=\"min\",\n",
    "            scheduler=scheduler,\n",
    "            num_samples=config[\"num_trials\"],\n",
    "        ),\n",
    "        param_space=config,\n",
    "    )\n",
    "\n",
    "    results = tuner.fit()\n",
    "    best_result = results.get_best_result(\"val_loss\", \"min\")\n",
    "\n",
    "    print(\"üèÜ Best trial config:\", best_result.config)\n",
    "    print(\"üèÜ Best val_loss:\", best_result.metrics[\"val_loss\"])\n",
    "    print(\"üèÜ Best val_accuracy:\", best_result.metrics[\"val_accuracy\"])\n",
    "\n",
    "    test_best_model(best_result, model_cls, feature_dim, df)\n",
    "\n",
    "    config = {\n",
    "    \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "    \"batch_size\": tune.choice([16, 32, 64]),\n",
    "    \"optimizer\": tune.choice([\"adam\", \"sgd\"]),\n",
    "    \"weight_decay\": tune.loguniform(1e-5, 1e-2),\n",
    "    \"max_num_epochs\": 40,\n",
    "    \"num_trials\": 10,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "}\n",
    "\n",
    "model_cls = LogisticRgressionModel\n",
    "feature_dim = 8\n",
    "gpus_per_trial = 1 if torch.cuda.is_available() else 0\n",
    "\n",
    "run_ray_tune_aim(config, model_cls, feature_dim, df, gpus_per_trial)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Result(\n",
       "  metrics={'train_loss': 0.47168173509485584, 'train_accuracy': 0.776536312849162, 'val_loss': 0.4854586720466614, 'val_accuracy': 0.7391304347826086},\n",
       "  path='/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_854db_00000_0_batch_size=32,lr=0.0089,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-03-36',\n",
       "  filesystem='local',\n",
       "  checkpoint=Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/ray_tune_diabetes/train_using_tune_854db_00000_0_batch_size=32,lr=0.0089,optimizer=sgd,weight_decay=0.0000_2026-01-28_15-03-36/checkpoint_000029)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_result = tuner.get_results().get_best_result(\"val_loss\", \"min\")\n",
    "best_result"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
