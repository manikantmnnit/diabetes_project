{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummy dataset\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import torch\n",
    "from torch import Generator\n",
    "from torch.utils.data import DataLoader,Dataset, dataloader,random_split\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "\n",
    "import dagshub\n",
    "import mlflow\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "\n",
    "# hp tunning library\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2026-01-23 04:01:10--  https://raw.githubusercontent.com/npradaschnor/Pima-Indians-Diabetes-Dataset/master/diabetes.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 23105 (23K) [text/plain]\n",
      "Saving to: ‚Äòdiabetes.csv.6‚Äô\n",
      "\n",
      "diabetes.csv.6      100%[===================>]  22.56K  --.-KB/s    in 0s      \n",
      "\n",
      "2026-01-23 04:01:10 (152 MB/s) - ‚Äòdiabetes.csv.6‚Äô saved [23105/23105]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/npradaschnor/Pima-Indians-Diabetes-Dataset/master/diabetes.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import stack_size\n",
    "\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/npradaschnor/Pima-Indians-Diabetes-Dataset/master/diabetes.csv\"\n",
    "\n",
    "# Read the data\n",
    "df = pd.read_csv(url)\n",
    "df.head()\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DiabeticDataset(Dataset):\n",
    "    X:torch.Tensor\n",
    "    y:torch.Tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        return self.X[idx],self.y[idx]\n",
    "\n",
    "# normalization\n",
    "class Normalization_dataset(Dataset):\n",
    "    def __init__(self, base_dataset, mean, std):\n",
    "        self.base_dataset = base_dataset\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "        # üî• preserve indices if base_dataset is a Subset\n",
    "        if hasattr(base_dataset, \"indices\"):\n",
    "            self.indices = base_dataset.indices\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X, y = self.base_dataset[idx]\n",
    "        X = (X - self.mean) / (self.std + 1e-8)\n",
    "        return X, y\n",
    "\n",
    "class DiabeticDataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        batch_size=16,\n",
    "        train_ratio=0.7,\n",
    "        val_ratio=0.15,\n",
    "        seed=40\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.batch_size = batch_size\n",
    "        self.train_ratio = train_ratio\n",
    "        self.val_ratio = val_ratio\n",
    "        self.seed = seed\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        X = self.df.drop(columns=\"Outcome\", axis=1).values\n",
    "        y = self.df[\"Outcome\"].values\n",
    "\n",
    "        # convert into tensors\n",
    "        X = torch.tensor(X, dtype=torch.float32)\n",
    "        y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "        full_dataset = DiabeticDataset(X, y)\n",
    "\n",
    "        n_total = len(full_dataset)\n",
    "        n_train = int(self.train_ratio * n_total)\n",
    "        n_val   = int(self.val_ratio * n_total)\n",
    "        n_test  = n_total - n_train - n_val\n",
    "\n",
    "        generator = torch.Generator().manual_seed(self.seed)\n",
    "\n",
    "        self.train_ds, self.val_ds, self.test_ds = random_split(\n",
    "            full_dataset,\n",
    "            [n_train, n_val, n_test],\n",
    "            generator=generator\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_ds,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            pin_memory=True,\n",
    "            drop_last=False\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_ds,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            pin_memory=True,\n",
    "            drop_last=False\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_ds,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            pin_memory=True,\n",
    "            drop_last=False\n",
    "        )\n",
    "\n",
    "    # ---------- Normalization (fit on train only) ----------\n",
    "    def normalize_datasets(self):\n",
    "        X_all = []\n",
    "\n",
    "        for X, y in self.train_dataloader():\n",
    "            X_all.append(X.cpu())\n",
    "\n",
    "        X_all = torch.cat(X_all, dim=0)\n",
    "\n",
    "        mean = X_all.mean(dim=0)\n",
    "        std  = X_all.std(dim=0)\n",
    "\n",
    "        # Wrap datasets\n",
    "        self.train_ds = Normalization_dataset(self.train_ds, mean, std)\n",
    "        self.val_ds   = Normalization_dataset(self.val_ds,   mean, std)\n",
    "        self.test_ds  = Normalization_dataset(self.test_ds,  mean, std)\n",
    "\n",
    "        return mean, std\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: tensor([  3.8827, 120.9534,  69.1899,  19.9590,  77.6369,  31.8946,   0.4689,\n",
      "         33.2737])\n",
      "Std: tensor([  3.3960,  32.1912,  19.6791,  16.0622, 112.1099,   7.9516,   0.3178,\n",
      "         11.5753])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "dm = DiabeticDataModule(df=df, seed=36)\n",
    "dm.setup()\n",
    "\n",
    "mean, std = dm.normalize_datasets()\n",
    "\n",
    "train_loader = dm.train_dataloader()\n",
    "test_loader  = dm.test_dataloader()\n",
    "valid_loader=dm.val_dataloader()\n",
    "\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Std:\", std)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 8]), torch.Size([16]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify the dataset\n",
    "type(dm.train_ds[0][1])\n",
    "X,y=next(iter(train_loader))\n",
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect train data\n",
    "X_train_list = []\n",
    "y_train_list = []\n",
    "\n",
    "for x, y in train_loader.dataset:\n",
    "    X_train_list.append(x)\n",
    "    y_train_list.append(y)\n",
    "\n",
    "X_train = torch.stack(X_train_list, dim=0)  # (N_train, num_features)\n",
    "y_train = torch.tensor(y_train_list)         # (N_train,)\n",
    "\n",
    "# Collect test data\n",
    "X_test_list = []\n",
    "y_test_list = []\n",
    "\n",
    "for x, y in test_loader.dataset:\n",
    "    X_test_list.append(x)\n",
    "    y_test_list.append(y)\n",
    "\n",
    "X_test = torch.stack(X_test_list, dim=0)   # (N_test, num_features)\n",
    "y_test = torch.tensor(y_test_list)    \n",
    "\n",
    "from pathlib import Path\n",
    "save_dir=Path.cwd().parent/'data'/'splits'\n",
    "save_dir.mkdir(parents=True,exist_ok=True)\n",
    "\n",
    "# File path\n",
    "save_path = save_dir / \"diabetes_normalized.pt\"\n",
    "\n",
    "torch.save({\n",
    "    \"X_train\": X_train,\n",
    "    \"y_train\": y_train,\n",
    "    \"X_test\": X_test,\n",
    "    \"y_test\": y_test\n",
    "}, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save split data inot csv and store in dvc\n",
    "train_indices=dm.train_ds.indices\n",
    "test_indices=dm.test_ds.indices\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "data_dir=Path.cwd().parent/'data'\n",
    "# Create 'splits' folder inside 'data' directory\n",
    "splits_dir = data_dir / 'splits'\n",
    "\n",
    "splits_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df.iloc[train_indices].to_csv(splits_dir / 'train.csv', index=False)\n",
    "df.iloc[test_indices].to_csv(splits_dir / 'test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# basic algo: logistic_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic algo: logistic Algorithm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LogisticRgressionModel(nn.Module):\n",
    "    def __init__(self, featur_dim):\n",
    "        super().__init__()\n",
    "        self.linear=nn.Linear(featur_dim,1)   # single output either 0 or 1\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# setup model , loss and optimizer\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "featur_dim=8\n",
    "\n",
    "model=LogisticRgressionModel(featur_dim=featur_dim)\n",
    "\n",
    "lr=0.001\n",
    "\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=lr)\n",
    "\n",
    "criterion=nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct=0\n",
    "    total=0\n",
    "\n",
    "    for X, y in loader:\n",
    "        X = X.to(device)\n",
    "        y = y.float().unsqueeze(1).to(device)  # (batch, 1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X)\n",
    "        loss = criterion(logits, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # accuracy\n",
    "        probs=torch.sigmoid(logits)\n",
    "        predicts=(probs>0.5).long()\n",
    "        correct += (predicts == y.long()).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "\n",
    "    return total_loss / len(loader),correct/total\n",
    "\n",
    "def evaluate(model,loader,device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in loader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            logits = model(X)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            preds = (probs > 0.5).long().squeeze(1)\n",
    "\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "    return correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as manikantmnnit\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as manikantmnnit\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"manikantmnnit/diabetes_project\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"manikantmnnit/diabetes_project\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository manikantmnnit/diabetes_project initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository manikantmnnit/diabetes_project initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50] | Loss: 0.6694 | Train Acc: 0.5996 | Test Acc: 0.5517\n",
      "Epoch [10/50] | Loss: 0.5999 | Train Acc: 0.7244 | Test Acc: 0.6810\n",
      "Epoch [15/50] | Loss: 0.5635 | Train Acc: 0.7505 | Test Acc: 0.7328\n",
      "Epoch [20/50] | Loss: 0.5381 | Train Acc: 0.7486 | Test Acc: 0.7586\n",
      "Epoch [25/50] | Loss: 0.5234 | Train Acc: 0.7523 | Test Acc: 0.7586\n",
      "Epoch [30/50] | Loss: 0.5093 | Train Acc: 0.7542 | Test Acc: 0.7414\n",
      "Epoch [35/50] | Loss: 0.4999 | Train Acc: 0.7542 | Test Acc: 0.7759\n",
      "Epoch [40/50] | Loss: 0.4951 | Train Acc: 0.7598 | Test Acc: 0.7759\n",
      "Epoch [45/50] | Loss: 0.4919 | Train Acc: 0.7635 | Test Acc: 0.7759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/23 04:03:36 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50] | Loss: 0.4879 | Train Acc: 0.7728 | Test Acc: 0.7845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/23 04:03:44 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cu128) contains a local version label (+cu128). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2026/01/23 04:03:50 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.23.0+cu128) contains a local version label (+cu128). MLflow logged a pip requirement for this package as 'torchvision==0.23.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run log_reg_baseline at: https://dagshub.com/manikantmnnit/diabetes_project.mlflow/#/experiments/0/runs/3a992a4b3c6c4589bac8351bceb9cd37\n",
      "üß™ View experiment at: https://dagshub.com/manikantmnnit/diabetes_project.mlflow/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "import dagshub\n",
    "dagshub.init(repo_owner='manikantmnnit', repo_name='diabetes_project', mlflow=True)\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri('https://dagshub.com/manikantmnnit/diabetes_project.mlflow')\n",
    "\n",
    "num_epochs = 50\n",
    "mlflow.set_experiment(\"diabetes_logistic_regression\")\n",
    "with mlflow.start_run(run_name='log_reg_baseline'):\n",
    "    mlflow.log_param(\"model\", \"logistic_regression\")\n",
    "    mlflow.log_param(\"optimizer\", \"Adam\")\n",
    "    mlflow.log_param(\"learning_rate\", lr)\n",
    "    mlflow.log_param('Batch_size',num_epochs)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss,train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        test_acc   = evaluate(model, test_loader, device)\n",
    "\n",
    "        # ---- Log metrics per epoch ----\n",
    "        mlflow.log_metric(\"train_log_loss\", train_loss, step=epoch)\n",
    "        mlflow.log_metric(\"train_accuracy\", train_acc, step=epoch)\n",
    "        mlflow.log_metric(\"test_accuracy\", test_acc, step=epoch)\n",
    "\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch+1}/{num_epochs}] | \"\n",
    "                f\"Loss: {train_loss:.4f} | \"\n",
    "                f\"Train Acc: {train_acc:.4f} | \"\n",
    "                f\"Test Acc: {test_acc:.4f}\"\n",
    "            )\n",
    "    \n",
    "    # log model\n",
    "    mlflow.pytorch.log_model(model,artifact_path='model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Ray Tune for HP tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "\n",
    "def train_using_tune(config, train_loader, valid_loader, model_cls, feature_dim,df):\n",
    "\n",
    "    device = config[\"device\"]\n",
    "    batch_size = int(config[\"batch_size\"])\n",
    "    lr = config[\"lr\"]\n",
    "\n",
    "    # üîπ Build DataModule INSIDE trial\n",
    "    dm = DiabeticDataModule(\n",
    "        df=df,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    dm.setup()\n",
    "    dm.normalize_datasets()\n",
    "\n",
    "    train_loader = dm.train_dataloader()\n",
    "    valid_loader = dm.val_dataloader()\n",
    "    test_loader  = dm.test_dataloader()\n",
    "\n",
    "    # Build model\n",
    "    model = model_cls(feature_dim).to(device)\n",
    "\n",
    "    # üîπ optimizer\n",
    "    if config[\"optimizer\"] == \"adam\":\n",
    "        optimizer = torch.optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr=config[\"lr\"],\n",
    "            weight_decay=config[\"weight_decay\"]\n",
    "        )\n",
    "    else:\n",
    "        optimizer = torch.optim.SGD(\n",
    "            model.parameters(),\n",
    "            lr=config[\"lr\"],\n",
    "            momentum=0.9,\n",
    "            weight_decay=config[\"weight_decay\"]\n",
    "        )\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # ----- Restore checkpoint if exists -----\n",
    "    checkpoint = tune.get_checkpoint()\n",
    "    if checkpoint:\n",
    "        with checkpoint.as_directory() as ckpt_dir:\n",
    "            model_state, optimizer_state = torch.load(\n",
    "                os.path.join(ckpt_dir, \"checkpoint.pt\"),\n",
    "                map_location=device\n",
    "            )\n",
    "            model.load_state_dict(model_state)\n",
    "            optimizer.load_state_dict(optimizer_state)\n",
    "\n",
    "    # ----- Training loop -----\n",
    "    max_epochs = config[\"max_num_epochs\"]\n",
    "    for epoch in range(max_epochs):\n",
    "\n",
    "        # ===== Train =====\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        for X, y in train_loader:\n",
    "            X = X.to(device)\n",
    "            y = y.float().unsqueeze(1).to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(X) # forward\n",
    "            loss = criterion(logits, y)\n",
    "\n",
    "            loss.backward()  # back propagation\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "            probs = torch.sigmoid(logits)\n",
    "            preds = (probs > 0.5).long()\n",
    "            correct_train += (preds == y.long()).sum().item()\n",
    "            total_train += y.size(0)\n",
    "\n",
    "        train_loss = total_train_loss / len(train_loader)\n",
    "        train_acc = correct_train / total_train\n",
    "\n",
    "        # ===== Validation =====\n",
    "        model.eval()\n",
    "        total_val_loss = 0.0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X, y in valid_loader:\n",
    "                X = X.to(device)\n",
    "                y = y.float().unsqueeze(1).to(device)\n",
    "\n",
    "                logits = model(X)\n",
    "                loss = criterion(logits, y)\n",
    "\n",
    "                total_val_loss += loss.item()\n",
    "\n",
    "                probs = torch.sigmoid(logits)\n",
    "                preds = (probs > 0.5).long()\n",
    "                correct_val += (preds == y.long()).sum().item()\n",
    "                total_val += y.size(0)\n",
    "\n",
    "        val_loss = total_val_loss / len(valid_loader)\n",
    "        val_acc = correct_val / total_val\n",
    "\n",
    "        # ===== Save checkpoint + report =====\n",
    "        with tempfile.TemporaryDirectory() as temp_checkpoint_dir:\n",
    "            ckpt_path = os.path.join(temp_checkpoint_dir, \"checkpoint.pt\")\n",
    "            torch.save((model.state_dict(), optimizer.state_dict()), ckpt_path)\n",
    "\n",
    "            checkpoint = tune.Checkpoint.from_directory(temp_checkpoint_dir)\n",
    "\n",
    "            tune.report(\n",
    "                {\n",
    "                    \"train_loss\": train_loss,\n",
    "                    \"train_accuracy\": train_acc,\n",
    "                    \"val_loss\": val_loss,\n",
    "                    \"val_accuracy\": val_acc,\n",
    "                },\n",
    "                checkpoint=checkpoint\n",
    "            )\n",
    "\n",
    "\n",
    "# obtain best accurac based on best model uisng checkpoint\n",
    "def test_best_model(best_result, test_loader, model_cls, feature_dim):\n",
    "\n",
    "    device = best_result.config[\"device\"]\n",
    "\n",
    "    # Build model\n",
    "    best_trained_model = model_cls(feature_dim).to(device)\n",
    "\n",
    "    # ----- Load best checkpoint -----\n",
    "    checkpoint = best_result.checkpoint\n",
    "    with checkpoint.as_directory() as ckpt_dir:\n",
    "        checkpoint_path = os.path.join(ckpt_dir, \"checkpoint.pt\")\n",
    "        model_state, _ = torch.load(checkpoint_path, map_location=device)\n",
    "\n",
    "    best_trained_model.load_state_dict(model_state)\n",
    "    best_trained_model.eval()\n",
    "\n",
    "    # ----- Test loop -----\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_loader:\n",
    "            X = X.to(device)\n",
    "            y = y.float().unsqueeze(1).to(device)\n",
    "\n",
    "            logits = best_trained_model(X)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            preds = (probs > 0.5).long()\n",
    "\n",
    "            correct_test += (preds == y.long()).sum().item()\n",
    "            total_test += y.size(0)\n",
    "\n",
    "    print(f\"‚úÖ Best trial test set accuracy: {correct_test / total_test:.4f}\")\n",
    "\n",
    "\n",
    "# train the model, find best performing one and load the trained netqork from checkpoint file\n",
    "\n",
    "def main(config, train_loader, valid_loader, test_loader, model_cls,df, feature_dim, gpus_per_trial=1):\n",
    "\n",
    "    \n",
    "    scheduler = ASHAScheduler(\n",
    "        time_attr=\"training_iteration\",\n",
    "        max_t=config[\"max_num_epochs\"],\n",
    "        grace_period=1,\n",
    "        reduction_factor=2\n",
    "    )\n",
    "\n",
    "    tuner = tune.Tuner(\n",
    "        tune.with_resources(\n",
    "            tune.with_parameters(\n",
    "                train_using_tune,\n",
    "                train_loader=train_loader,\n",
    "                valid_loader=valid_loader,\n",
    "                model_cls=model_cls,\n",
    "                feature_dim=feature_dim,\n",
    "                df=df\n",
    "            ),\n",
    "            resources={\"cpu\": 4, \"gpu\": gpus_per_trial}\n",
    "        ),\n",
    "        tune_config=tune.TuneConfig(\n",
    "            metric=\"val_loss\",\n",
    "            mode=\"min\",\n",
    "            scheduler=scheduler,\n",
    "            num_samples=config[\"num_trials\"],\n",
    "        ),\n",
    "        param_space=config,\n",
    "    )\n",
    "\n",
    "    results = tuner.fit()\n",
    "\n",
    "    best_result = results.get_best_result(\"val_loss\", \"min\")\n",
    "\n",
    "    print(f\"üèÜ Best trial config: {best_result.config}\")\n",
    "    print(f\"üèÜ Best trial final validation loss: {best_result.metrics['val_loss']}\")\n",
    "    print(f\"üèÜ Best trial final validation accuracy: {best_result.metrics['val_accuracy']}\")\n",
    "\n",
    "    test_best_model(best_result, test_loader, model_cls, feature_dim)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_using_tune pid=150524)\u001b[0m /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "\u001b[36m(train_using_tune pid=150524)\u001b[0m   warnings.warn(warn_msg)\n",
      "\u001b[36m(train_using_tune pid=150524)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00000_0_batch_size=16,lr=0.0002,optimizer=sgd,weight_decay=0.0024_2026-01-23_04-49-27/checkpoint_000000)\n",
      "\u001b[36m(train_using_tune pid=150524)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00000_0_batch_size=16,lr=0.0002,optimizer=sgd,weight_decay=0.0024_2026-01-23_04-49-27/checkpoint_000001)\n",
      "\u001b[36m(train_using_tune pid=150524)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00000_0_batch_size=16,lr=0.0002,optimizer=sgd,weight_decay=0.0024_2026-01-23_04-49-27/checkpoint_000002)\n",
      "\u001b[36m(train_using_tune pid=150524)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00000_0_batch_size=16,lr=0.0002,optimizer=sgd,weight_decay=0.0024_2026-01-23_04-49-27/checkpoint_000003)\n",
      "\u001b[36m(train_using_tune pid=150524)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00000_0_batch_size=16,lr=0.0002,optimizer=sgd,weight_decay=0.0024_2026-01-23_04-49-27/checkpoint_000004)\n",
      "\u001b[36m(train_using_tune pid=150524)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00000_0_batch_size=16,lr=0.0002,optimizer=sgd,weight_decay=0.0024_2026-01-23_04-49-27/checkpoint_000005)\n",
      "\u001b[36m(train_using_tune pid=150524)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00000_0_batch_size=16,lr=0.0002,optimizer=sgd,weight_decay=0.0024_2026-01-23_04-49-27/checkpoint_000006)\n",
      "\u001b[36m(train_using_tune pid=150524)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00000_0_batch_size=16,lr=0.0002,optimizer=sgd,weight_decay=0.0024_2026-01-23_04-49-27/checkpoint_000007)\n",
      "\u001b[36m(train_using_tune pid=150524)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00000_0_batch_size=16,lr=0.0002,optimizer=sgd,weight_decay=0.0024_2026-01-23_04-49-27/checkpoint_000008)\n",
      "\u001b[36m(train_using_tune pid=150524)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00000_0_batch_size=16,lr=0.0002,optimizer=sgd,weight_decay=0.0024_2026-01-23_04-49-27/checkpoint_000009)\n",
      "\u001b[36m(train_using_tune pid=150524)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00000_0_batch_size=16,lr=0.0002,optimizer=sgd,weight_decay=0.0024_2026-01-23_04-49-27/checkpoint_000010)\n",
      "\u001b[36m(train_using_tune pid=150524)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00000_0_batch_size=16,lr=0.0002,optimizer=sgd,weight_decay=0.0024_2026-01-23_04-49-27/checkpoint_000011)\n",
      "\u001b[36m(train_using_tune pid=150524)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00000_0_batch_size=16,lr=0.0002,optimizer=sgd,weight_decay=0.0024_2026-01-23_04-49-27/checkpoint_000012)\n",
      "\u001b[36m(train_using_tune pid=150524)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00000_0_batch_size=16,lr=0.0002,optimizer=sgd,weight_decay=0.0024_2026-01-23_04-49-27/checkpoint_000013)\n",
      "\u001b[36m(train_using_tune pid=150524)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00000_0_batch_size=16,lr=0.0002,optimizer=sgd,weight_decay=0.0024_2026-01-23_04-49-27/checkpoint_000014)\n",
      "\u001b[36m(train_using_tune pid=150524)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00000_0_batch_size=16,lr=0.0002,optimizer=sgd,weight_decay=0.0024_2026-01-23_04-49-27/checkpoint_000015)\n",
      "\u001b[36m(train_using_tune pid=150524)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00000_0_batch_size=16,lr=0.0002,optimizer=sgd,weight_decay=0.0024_2026-01-23_04-49-27/checkpoint_000016)\n",
      "\u001b[36m(train_using_tune pid=150524)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00000_0_batch_size=16,lr=0.0002,optimizer=sgd,weight_decay=0.0024_2026-01-23_04-49-27/checkpoint_000017)\n",
      "\u001b[36m(train_using_tune pid=150524)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00000_0_batch_size=16,lr=0.0002,optimizer=sgd,weight_decay=0.0024_2026-01-23_04-49-27/checkpoint_000018)\n",
      "\u001b[36m(train_using_tune pid=150524)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00000_0_batch_size=16,lr=0.0002,optimizer=sgd,weight_decay=0.0024_2026-01-23_04-49-27/checkpoint_000019)\n",
      "\u001b[36m(train_using_tune pid=150524)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00000_0_batch_size=16,lr=0.0002,optimizer=sgd,weight_decay=0.0024_2026-01-23_04-49-27/checkpoint_000020)\n",
      "\u001b[36m(train_using_tune pid=150524)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00000_0_batch_size=16,lr=0.0002,optimizer=sgd,weight_decay=0.0024_2026-01-23_04-49-27/checkpoint_000021)\n",
      "\u001b[36m(train_using_tune pid=150524)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00000_0_batch_size=16,lr=0.0002,optimizer=sgd,weight_decay=0.0024_2026-01-23_04-49-27/checkpoint_000022)\n",
      "\u001b[36m(train_using_tune pid=150524)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00000_0_batch_size=16,lr=0.0002,optimizer=sgd,weight_decay=0.0024_2026-01-23_04-49-27/checkpoint_000023)\n",
      "\u001b[36m(train_using_tune pid=150524)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00000_0_batch_size=16,lr=0.0002,optimizer=sgd,weight_decay=0.0024_2026-01-23_04-49-27/checkpoint_000024)\n",
      "\u001b[36m(train_using_tune pid=150524)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00000_0_batch_size=16,lr=0.0002,optimizer=sgd,weight_decay=0.0024_2026-01-23_04-49-27/checkpoint_000025)\n",
      "\u001b[36m(train_using_tune pid=150524)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00000_0_batch_size=16,lr=0.0002,optimizer=sgd,weight_decay=0.0024_2026-01-23_04-49-27/checkpoint_000026)\n",
      "\u001b[36m(train_using_tune pid=150524)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00000_0_batch_size=16,lr=0.0002,optimizer=sgd,weight_decay=0.0024_2026-01-23_04-49-27/checkpoint_000027)\n",
      "\u001b[36m(train_using_tune pid=150524)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00000_0_batch_size=16,lr=0.0002,optimizer=sgd,weight_decay=0.0024_2026-01-23_04-49-27/checkpoint_000028)\n",
      "\u001b[36m(train_using_tune pid=150524)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00000_0_batch_size=16,lr=0.0002,optimizer=sgd,weight_decay=0.0024_2026-01-23_04-49-27/checkpoint_000029)\n",
      "\u001b[36m(train_using_tune pid=151355)\u001b[0m /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "\u001b[36m(train_using_tune pid=151355)\u001b[0m   warnings.warn(warn_msg)\n",
      "\u001b[36m(train_using_tune pid=151355)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00001_1_batch_size=32,lr=0.0026,optimizer=sgd,weight_decay=0.0003_2026-01-23_04-49-27/checkpoint_000000)\n",
      "\u001b[36m(train_using_tune pid=151355)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00001_1_batch_size=32,lr=0.0026,optimizer=sgd,weight_decay=0.0003_2026-01-23_04-49-27/checkpoint_000001)\n",
      "\u001b[36m(train_using_tune pid=151355)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00001_1_batch_size=32,lr=0.0026,optimizer=sgd,weight_decay=0.0003_2026-01-23_04-49-27/checkpoint_000002)\n",
      "\u001b[36m(train_using_tune pid=151355)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00001_1_batch_size=32,lr=0.0026,optimizer=sgd,weight_decay=0.0003_2026-01-23_04-49-27/checkpoint_000003)\n",
      "\u001b[36m(train_using_tune pid=151355)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00001_1_batch_size=32,lr=0.0026,optimizer=sgd,weight_decay=0.0003_2026-01-23_04-49-27/checkpoint_000004)\n",
      "\u001b[36m(train_using_tune pid=151355)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00001_1_batch_size=32,lr=0.0026,optimizer=sgd,weight_decay=0.0003_2026-01-23_04-49-27/checkpoint_000005)\n",
      "\u001b[36m(train_using_tune pid=151355)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00001_1_batch_size=32,lr=0.0026,optimizer=sgd,weight_decay=0.0003_2026-01-23_04-49-27/checkpoint_000006)\n",
      "\u001b[36m(train_using_tune pid=151355)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00001_1_batch_size=32,lr=0.0026,optimizer=sgd,weight_decay=0.0003_2026-01-23_04-49-27/checkpoint_000007)\n",
      "\u001b[36m(train_using_tune pid=151355)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00001_1_batch_size=32,lr=0.0026,optimizer=sgd,weight_decay=0.0003_2026-01-23_04-49-27/checkpoint_000008)\n",
      "\u001b[36m(train_using_tune pid=151355)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00001_1_batch_size=32,lr=0.0026,optimizer=sgd,weight_decay=0.0003_2026-01-23_04-49-27/checkpoint_000009)\n",
      "\u001b[36m(train_using_tune pid=151355)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00001_1_batch_size=32,lr=0.0026,optimizer=sgd,weight_decay=0.0003_2026-01-23_04-49-27/checkpoint_000010)\n",
      "\u001b[36m(train_using_tune pid=151355)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00001_1_batch_size=32,lr=0.0026,optimizer=sgd,weight_decay=0.0003_2026-01-23_04-49-27/checkpoint_000011)\n",
      "\u001b[36m(train_using_tune pid=151355)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00001_1_batch_size=32,lr=0.0026,optimizer=sgd,weight_decay=0.0003_2026-01-23_04-49-27/checkpoint_000012)\n",
      "\u001b[36m(train_using_tune pid=151355)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00001_1_batch_size=32,lr=0.0026,optimizer=sgd,weight_decay=0.0003_2026-01-23_04-49-27/checkpoint_000013)\n",
      "\u001b[36m(train_using_tune pid=151355)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00001_1_batch_size=32,lr=0.0026,optimizer=sgd,weight_decay=0.0003_2026-01-23_04-49-27/checkpoint_000014)\n",
      "\u001b[36m(train_using_tune pid=151355)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00001_1_batch_size=32,lr=0.0026,optimizer=sgd,weight_decay=0.0003_2026-01-23_04-49-27/checkpoint_000015)\n",
      "\u001b[36m(train_using_tune pid=151355)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00001_1_batch_size=32,lr=0.0026,optimizer=sgd,weight_decay=0.0003_2026-01-23_04-49-27/checkpoint_000016)\n",
      "\u001b[36m(train_using_tune pid=151355)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00001_1_batch_size=32,lr=0.0026,optimizer=sgd,weight_decay=0.0003_2026-01-23_04-49-27/checkpoint_000017)\n",
      "\u001b[36m(train_using_tune pid=151355)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00001_1_batch_size=32,lr=0.0026,optimizer=sgd,weight_decay=0.0003_2026-01-23_04-49-27/checkpoint_000018)\n",
      "\u001b[36m(train_using_tune pid=151355)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00001_1_batch_size=32,lr=0.0026,optimizer=sgd,weight_decay=0.0003_2026-01-23_04-49-27/checkpoint_000019)\n",
      "\u001b[36m(train_using_tune pid=151355)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00001_1_batch_size=32,lr=0.0026,optimizer=sgd,weight_decay=0.0003_2026-01-23_04-49-27/checkpoint_000020)\n",
      "\u001b[36m(train_using_tune pid=151355)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00001_1_batch_size=32,lr=0.0026,optimizer=sgd,weight_decay=0.0003_2026-01-23_04-49-27/checkpoint_000021)\n",
      "\u001b[36m(train_using_tune pid=151355)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00001_1_batch_size=32,lr=0.0026,optimizer=sgd,weight_decay=0.0003_2026-01-23_04-49-27/checkpoint_000022)\n",
      "\u001b[36m(train_using_tune pid=151355)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00001_1_batch_size=32,lr=0.0026,optimizer=sgd,weight_decay=0.0003_2026-01-23_04-49-27/checkpoint_000023)\n",
      "\u001b[36m(train_using_tune pid=151355)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00001_1_batch_size=32,lr=0.0026,optimizer=sgd,weight_decay=0.0003_2026-01-23_04-49-27/checkpoint_000024)\n",
      "\u001b[36m(train_using_tune pid=151355)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00001_1_batch_size=32,lr=0.0026,optimizer=sgd,weight_decay=0.0003_2026-01-23_04-49-27/checkpoint_000025)\n",
      "\u001b[36m(train_using_tune pid=151355)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00001_1_batch_size=32,lr=0.0026,optimizer=sgd,weight_decay=0.0003_2026-01-23_04-49-27/checkpoint_000026)\n",
      "\u001b[36m(train_using_tune pid=151355)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00001_1_batch_size=32,lr=0.0026,optimizer=sgd,weight_decay=0.0003_2026-01-23_04-49-27/checkpoint_000027)\n",
      "\u001b[36m(train_using_tune pid=151355)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00001_1_batch_size=32,lr=0.0026,optimizer=sgd,weight_decay=0.0003_2026-01-23_04-49-27/checkpoint_000028)\n",
      "\u001b[36m(train_using_tune pid=151355)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00001_1_batch_size=32,lr=0.0026,optimizer=sgd,weight_decay=0.0003_2026-01-23_04-49-27/checkpoint_000029)\n",
      "\u001b[36m(train_using_tune pid=151828)\u001b[0m /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "\u001b[36m(train_using_tune pid=151828)\u001b[0m   warnings.warn(warn_msg)\n",
      "\u001b[36m(train_using_tune pid=151828)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00002_2_batch_size=64,lr=0.0005,optimizer=adam,weight_decay=0.0034_2026-01-23_04-49-27/checkpoint_000000)\n",
      "\u001b[36m(train_using_tune pid=152293)\u001b[0m /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "\u001b[36m(train_using_tune pid=152293)\u001b[0m   warnings.warn(warn_msg)\n",
      "\u001b[36m(train_using_tune pid=152293)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00003_3_batch_size=32,lr=0.0277,optimizer=adam,weight_decay=0.0004_2026-01-23_04-49-27/checkpoint_000000)\n",
      "\u001b[36m(train_using_tune pid=152293)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00003_3_batch_size=32,lr=0.0277,optimizer=adam,weight_decay=0.0004_2026-01-23_04-49-27/checkpoint_000001)\n",
      "\u001b[36m(train_using_tune pid=152293)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00003_3_batch_size=32,lr=0.0277,optimizer=adam,weight_decay=0.0004_2026-01-23_04-49-27/checkpoint_000002)\n",
      "\u001b[36m(train_using_tune pid=152293)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00003_3_batch_size=32,lr=0.0277,optimizer=adam,weight_decay=0.0004_2026-01-23_04-49-27/checkpoint_000003)\n",
      "\u001b[36m(train_using_tune pid=152293)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00003_3_batch_size=32,lr=0.0277,optimizer=adam,weight_decay=0.0004_2026-01-23_04-49-27/checkpoint_000004)\n",
      "\u001b[36m(train_using_tune pid=152293)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00003_3_batch_size=32,lr=0.0277,optimizer=adam,weight_decay=0.0004_2026-01-23_04-49-27/checkpoint_000005)\n",
      "\u001b[36m(train_using_tune pid=152293)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00003_3_batch_size=32,lr=0.0277,optimizer=adam,weight_decay=0.0004_2026-01-23_04-49-27/checkpoint_000006)\n",
      "\u001b[36m(train_using_tune pid=152293)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00003_3_batch_size=32,lr=0.0277,optimizer=adam,weight_decay=0.0004_2026-01-23_04-49-27/checkpoint_000007)\n",
      "\u001b[36m(train_using_tune pid=152293)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00003_3_batch_size=32,lr=0.0277,optimizer=adam,weight_decay=0.0004_2026-01-23_04-49-27/checkpoint_000008)\n",
      "\u001b[36m(train_using_tune pid=152293)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00003_3_batch_size=32,lr=0.0277,optimizer=adam,weight_decay=0.0004_2026-01-23_04-49-27/checkpoint_000009)\n",
      "\u001b[36m(train_using_tune pid=152293)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00003_3_batch_size=32,lr=0.0277,optimizer=adam,weight_decay=0.0004_2026-01-23_04-49-27/checkpoint_000010)\n",
      "\u001b[36m(train_using_tune pid=152293)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00003_3_batch_size=32,lr=0.0277,optimizer=adam,weight_decay=0.0004_2026-01-23_04-49-27/checkpoint_000011)\n",
      "\u001b[36m(train_using_tune pid=152293)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00003_3_batch_size=32,lr=0.0277,optimizer=adam,weight_decay=0.0004_2026-01-23_04-49-27/checkpoint_000012)\n",
      "\u001b[36m(train_using_tune pid=152293)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00003_3_batch_size=32,lr=0.0277,optimizer=adam,weight_decay=0.0004_2026-01-23_04-49-27/checkpoint_000013)\n",
      "\u001b[36m(train_using_tune pid=152293)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00003_3_batch_size=32,lr=0.0277,optimizer=adam,weight_decay=0.0004_2026-01-23_04-49-27/checkpoint_000014)\n",
      "\u001b[36m(train_using_tune pid=152293)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00003_3_batch_size=32,lr=0.0277,optimizer=adam,weight_decay=0.0004_2026-01-23_04-49-27/checkpoint_000015)\n",
      "\u001b[36m(train_using_tune pid=152293)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00003_3_batch_size=32,lr=0.0277,optimizer=adam,weight_decay=0.0004_2026-01-23_04-49-27/checkpoint_000016)\n",
      "\u001b[36m(train_using_tune pid=152293)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00003_3_batch_size=32,lr=0.0277,optimizer=adam,weight_decay=0.0004_2026-01-23_04-49-27/checkpoint_000017)\n",
      "\u001b[36m(train_using_tune pid=152293)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00003_3_batch_size=32,lr=0.0277,optimizer=adam,weight_decay=0.0004_2026-01-23_04-49-27/checkpoint_000018)\n",
      "\u001b[36m(train_using_tune pid=152293)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00003_3_batch_size=32,lr=0.0277,optimizer=adam,weight_decay=0.0004_2026-01-23_04-49-27/checkpoint_000019)\n",
      "\u001b[36m(train_using_tune pid=152293)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00003_3_batch_size=32,lr=0.0277,optimizer=adam,weight_decay=0.0004_2026-01-23_04-49-27/checkpoint_000020)\n",
      "\u001b[36m(train_using_tune pid=152293)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00003_3_batch_size=32,lr=0.0277,optimizer=adam,weight_decay=0.0004_2026-01-23_04-49-27/checkpoint_000021)\n",
      "\u001b[36m(train_using_tune pid=152293)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00003_3_batch_size=32,lr=0.0277,optimizer=adam,weight_decay=0.0004_2026-01-23_04-49-27/checkpoint_000022)\n",
      "\u001b[36m(train_using_tune pid=152293)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00003_3_batch_size=32,lr=0.0277,optimizer=adam,weight_decay=0.0004_2026-01-23_04-49-27/checkpoint_000023)\n",
      "\u001b[36m(train_using_tune pid=152293)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00003_3_batch_size=32,lr=0.0277,optimizer=adam,weight_decay=0.0004_2026-01-23_04-49-27/checkpoint_000024)\n",
      "\u001b[36m(train_using_tune pid=152293)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00003_3_batch_size=32,lr=0.0277,optimizer=adam,weight_decay=0.0004_2026-01-23_04-49-27/checkpoint_000025)\n",
      "\u001b[36m(train_using_tune pid=152293)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00003_3_batch_size=32,lr=0.0277,optimizer=adam,weight_decay=0.0004_2026-01-23_04-49-27/checkpoint_000026)\n",
      "\u001b[36m(train_using_tune pid=152293)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00003_3_batch_size=32,lr=0.0277,optimizer=adam,weight_decay=0.0004_2026-01-23_04-49-27/checkpoint_000027)\n",
      "\u001b[36m(train_using_tune pid=152293)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00003_3_batch_size=32,lr=0.0277,optimizer=adam,weight_decay=0.0004_2026-01-23_04-49-27/checkpoint_000028)\n",
      "\u001b[36m(train_using_tune pid=152293)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00003_3_batch_size=32,lr=0.0277,optimizer=adam,weight_decay=0.0004_2026-01-23_04-49-27/checkpoint_000029)\n",
      "\u001b[36m(train_using_tune pid=153125)\u001b[0m /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "\u001b[36m(train_using_tune pid=153125)\u001b[0m   warnings.warn(warn_msg)\n",
      "\u001b[36m(train_using_tune pid=153125)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00004_4_batch_size=32,lr=0.0074,optimizer=sgd,weight_decay=0.0000_2026-01-23_04-49-27/checkpoint_000000)\n",
      "\u001b[36m(train_using_tune pid=153591)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00005_5_batch_size=32,lr=0.0003,optimizer=adam,weight_decay=0.0000_2026-01-23_04-49-27/checkpoint_000000)\n",
      "\u001b[36m(train_using_tune pid=153591)\u001b[0m /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "\u001b[36m(train_using_tune pid=153591)\u001b[0m   warnings.warn(warn_msg)\n",
      "\u001b[36m(train_using_tune pid=154428)\u001b[0m /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "\u001b[36m(train_using_tune pid=154428)\u001b[0m   warnings.warn(warn_msg)\n",
      "\u001b[36m(train_using_tune pid=154428)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00006_6_batch_size=64,lr=0.0035,optimizer=sgd,weight_decay=0.0025_2026-01-23_04-49-27/checkpoint_000000)\n",
      "\u001b[36m(train_using_tune pid=154900)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00007_7_batch_size=64,lr=0.0036,optimizer=adam,weight_decay=0.0001_2026-01-23_04-49-27/checkpoint_000000)\n",
      "\u001b[36m(train_using_tune pid=154900)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00007_7_batch_size=64,lr=0.0036,optimizer=adam,weight_decay=0.0001_2026-01-23_04-49-27/checkpoint_000001)\n",
      "\u001b[36m(train_using_tune pid=154900)\u001b[0m /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "\u001b[36m(train_using_tune pid=154900)\u001b[0m   warnings.warn(warn_msg)\n",
      "\u001b[36m(train_using_tune pid=155376)\u001b[0m /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "\u001b[36m(train_using_tune pid=155376)\u001b[0m   warnings.warn(warn_msg)\n",
      "\u001b[36m(train_using_tune pid=155376)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00008_8_batch_size=64,lr=0.0007,optimizer=sgd,weight_decay=0.0002_2026-01-23_04-49-27/checkpoint_000000)\n",
      "\u001b[36m(train_using_tune pid=156202)\u001b[0m /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "\u001b[36m(train_using_tune pid=156202)\u001b[0m   warnings.warn(warn_msg)\n",
      "\u001b[36m(train_using_tune pid=156202)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00009_9_batch_size=64,lr=0.0925,optimizer=adam,weight_decay=0.0000_2026-01-23_04-49-27/checkpoint_000000)\n",
      "\u001b[36m(train_using_tune pid=156202)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00009_9_batch_size=64,lr=0.0925,optimizer=adam,weight_decay=0.0000_2026-01-23_04-49-27/checkpoint_000001)\n",
      "\u001b[36m(train_using_tune pid=156202)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00009_9_batch_size=64,lr=0.0925,optimizer=adam,weight_decay=0.0000_2026-01-23_04-49-27/checkpoint_000002)\n",
      "\u001b[36m(train_using_tune pid=156202)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00009_9_batch_size=64,lr=0.0925,optimizer=adam,weight_decay=0.0000_2026-01-23_04-49-27/checkpoint_000003)\n",
      "\u001b[36m(train_using_tune pid=156202)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00009_9_batch_size=64,lr=0.0925,optimizer=adam,weight_decay=0.0000_2026-01-23_04-49-27/checkpoint_000004)\n",
      "\u001b[36m(train_using_tune pid=156202)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00009_9_batch_size=64,lr=0.0925,optimizer=adam,weight_decay=0.0000_2026-01-23_04-49-27/checkpoint_000005)\n",
      "\u001b[36m(train_using_tune pid=156202)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00009_9_batch_size=64,lr=0.0925,optimizer=adam,weight_decay=0.0000_2026-01-23_04-49-27/checkpoint_000006)\n",
      "\u001b[36m(train_using_tune pid=156202)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00009_9_batch_size=64,lr=0.0925,optimizer=adam,weight_decay=0.0000_2026-01-23_04-49-27/checkpoint_000007)\n",
      "\u001b[36m(train_using_tune pid=156202)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00009_9_batch_size=64,lr=0.0925,optimizer=adam,weight_decay=0.0000_2026-01-23_04-49-27/checkpoint_000008)\n",
      "\u001b[36m(train_using_tune pid=156202)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00009_9_batch_size=64,lr=0.0925,optimizer=adam,weight_decay=0.0000_2026-01-23_04-49-27/checkpoint_000009)\n",
      "\u001b[36m(train_using_tune pid=156202)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00009_9_batch_size=64,lr=0.0925,optimizer=adam,weight_decay=0.0000_2026-01-23_04-49-27/checkpoint_000010)\n",
      "\u001b[36m(train_using_tune pid=156202)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00009_9_batch_size=64,lr=0.0925,optimizer=adam,weight_decay=0.0000_2026-01-23_04-49-27/checkpoint_000011)\n",
      "\u001b[36m(train_using_tune pid=156202)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00009_9_batch_size=64,lr=0.0925,optimizer=adam,weight_decay=0.0000_2026-01-23_04-49-27/checkpoint_000012)\n",
      "\u001b[36m(train_using_tune pid=156202)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00009_9_batch_size=64,lr=0.0925,optimizer=adam,weight_decay=0.0000_2026-01-23_04-49-27/checkpoint_000013)\n",
      "\u001b[36m(train_using_tune pid=156202)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00009_9_batch_size=64,lr=0.0925,optimizer=adam,weight_decay=0.0000_2026-01-23_04-49-27/checkpoint_000014)\n",
      "\u001b[36m(train_using_tune pid=156202)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00009_9_batch_size=64,lr=0.0925,optimizer=adam,weight_decay=0.0000_2026-01-23_04-49-27/checkpoint_000015)\n",
      "\u001b[36m(train_using_tune pid=156202)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00009_9_batch_size=64,lr=0.0925,optimizer=adam,weight_decay=0.0000_2026-01-23_04-49-27/checkpoint_000016)\n",
      "\u001b[36m(train_using_tune pid=156202)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00009_9_batch_size=64,lr=0.0925,optimizer=adam,weight_decay=0.0000_2026-01-23_04-49-27/checkpoint_000017)\n",
      "\u001b[36m(train_using_tune pid=156202)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00009_9_batch_size=64,lr=0.0925,optimizer=adam,weight_decay=0.0000_2026-01-23_04-49-27/checkpoint_000018)\n",
      "\u001b[36m(train_using_tune pid=156202)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00009_9_batch_size=64,lr=0.0925,optimizer=adam,weight_decay=0.0000_2026-01-23_04-49-27/checkpoint_000019)\n",
      "\u001b[36m(train_using_tune pid=156202)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00009_9_batch_size=64,lr=0.0925,optimizer=adam,weight_decay=0.0000_2026-01-23_04-49-27/checkpoint_000020)\n",
      "\u001b[36m(train_using_tune pid=156202)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00009_9_batch_size=64,lr=0.0925,optimizer=adam,weight_decay=0.0000_2026-01-23_04-49-27/checkpoint_000021)\n",
      "\u001b[36m(train_using_tune pid=156202)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00009_9_batch_size=64,lr=0.0925,optimizer=adam,weight_decay=0.0000_2026-01-23_04-49-27/checkpoint_000022)\n",
      "\u001b[36m(train_using_tune pid=156202)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00009_9_batch_size=64,lr=0.0925,optimizer=adam,weight_decay=0.0000_2026-01-23_04-49-27/checkpoint_000023)\n",
      "\u001b[36m(train_using_tune pid=156202)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00009_9_batch_size=64,lr=0.0925,optimizer=adam,weight_decay=0.0000_2026-01-23_04-49-27/checkpoint_000024)\n",
      "\u001b[36m(train_using_tune pid=156202)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00009_9_batch_size=64,lr=0.0925,optimizer=adam,weight_decay=0.0000_2026-01-23_04-49-27/checkpoint_000025)\n",
      "\u001b[36m(train_using_tune pid=156202)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00009_9_batch_size=64,lr=0.0925,optimizer=adam,weight_decay=0.0000_2026-01-23_04-49-27/checkpoint_000026)\n",
      "\u001b[36m(train_using_tune pid=156202)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00009_9_batch_size=64,lr=0.0925,optimizer=adam,weight_decay=0.0000_2026-01-23_04-49-27/checkpoint_000027)\n",
      "\u001b[36m(train_using_tune pid=156202)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00009_9_batch_size=64,lr=0.0925,optimizer=adam,weight_decay=0.0000_2026-01-23_04-49-27/checkpoint_000028)\n",
      "\u001b[36m(train_using_tune pid=156202)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00009_9_batch_size=64,lr=0.0925,optimizer=adam,weight_decay=0.0000_2026-01-23_04-49-27/checkpoint_000029)\n",
      "\u001b[36m(train_using_tune pid=156674)\u001b[0m /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "\u001b[36m(train_using_tune pid=156674)\u001b[0m   warnings.warn(warn_msg)\n",
      "\u001b[36m(train_using_tune pid=156674)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00010_10_batch_size=32,lr=0.0260,optimizer=sgd,weight_decay=0.0000_2026-01-23_04-49-27/checkpoint_000000)\n",
      "\u001b[36m(train_using_tune pid=156674)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00010_10_batch_size=32,lr=0.0260,optimizer=sgd,weight_decay=0.0000_2026-01-23_04-49-27/checkpoint_000001)\n",
      "\u001b[36m(train_using_tune pid=156674)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00010_10_batch_size=32,lr=0.0260,optimizer=sgd,weight_decay=0.0000_2026-01-23_04-49-27/checkpoint_000002)\n",
      "\u001b[36m(train_using_tune pid=156674)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00010_10_batch_size=32,lr=0.0260,optimizer=sgd,weight_decay=0.0000_2026-01-23_04-49-27/checkpoint_000003)\n",
      "\u001b[36m(train_using_tune pid=156674)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00010_10_batch_size=32,lr=0.0260,optimizer=sgd,weight_decay=0.0000_2026-01-23_04-49-27/checkpoint_000004)\n",
      "\u001b[36m(train_using_tune pid=156674)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00010_10_batch_size=32,lr=0.0260,optimizer=sgd,weight_decay=0.0000_2026-01-23_04-49-27/checkpoint_000005)\n",
      "\u001b[36m(train_using_tune pid=156674)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00010_10_batch_size=32,lr=0.0260,optimizer=sgd,weight_decay=0.0000_2026-01-23_04-49-27/checkpoint_000006)\n",
      "\u001b[36m(train_using_tune pid=156674)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00010_10_batch_size=32,lr=0.0260,optimizer=sgd,weight_decay=0.0000_2026-01-23_04-49-27/checkpoint_000007)\n",
      "\u001b[36m(train_using_tune pid=157144)\u001b[0m /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "\u001b[36m(train_using_tune pid=157144)\u001b[0m   warnings.warn(warn_msg)\n",
      "\u001b[36m(train_using_tune pid=157144)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00011_11_batch_size=64,lr=0.0067,optimizer=adam,weight_decay=0.0007_2026-01-23_04-49-27/checkpoint_000000)\n",
      "\u001b[36m(train_using_tune pid=157971)\u001b[0m /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "\u001b[36m(train_using_tune pid=157971)\u001b[0m   warnings.warn(warn_msg)\n",
      "\u001b[36m(train_using_tune pid=157971)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00012_12_batch_size=32,lr=0.0002,optimizer=adam,weight_decay=0.0007_2026-01-23_04-49-27/checkpoint_000000)\n",
      "\u001b[36m(train_using_tune pid=158443)\u001b[0m /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "\u001b[36m(train_using_tune pid=158443)\u001b[0m   warnings.warn(warn_msg)\n",
      "\u001b[36m(train_using_tune pid=158443)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00013_13_batch_size=64,lr=0.0885,optimizer=sgd,weight_decay=0.0001_2026-01-23_04-49-27/checkpoint_000001)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "2026-01-23 04:51:26,282\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27' in 0.0140s.\n",
      "2026-01-23 04:51:26,290\tINFO tune.py:1041 -- Total run time: 118.41 seconds (118.38 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÜ Best trial config: {'lr': 0.09245450318626276, 'batch_size': 64, 'optimizer': 'adam', 'weight_decay': 3.834196588142649e-06, 'max_num_epochs': 30, 'device': 'cpu', 'num_trials': 15}\n",
      "üèÜ Best trial final validation loss: 0.5341602861881256\n",
      "üèÜ Best trial final validation accuracy: 0.7217391304347827\n",
      "‚úÖ Best trial test set accuracy: 0.8103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_using_tune pid=159275)\u001b[0m /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "\u001b[36m(train_using_tune pid=159275)\u001b[0m   warnings.warn(warn_msg)\n",
      "\u001b[36m(train_using_tune pid=159275)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/teamspace/studios/this_studio/ray_results/train_using_tune_2026-01-23_04-49-27/train_using_tune_e5eb4_00014_14_batch_size=16,lr=0.0222,optimizer=adam,weight_decay=0.0000_2026-01-23_04-49-28/checkpoint_000001)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "config =  {\n",
    "    \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "    \"batch_size\": tune.choice([16, 32, 64]),\n",
    "    \"optimizer\": tune.choice([\"adam\", \"sgd\"]),\n",
    "    \"weight_decay\": tune.loguniform(1e-6, 1e-2),\n",
    "    \"max_num_epochs\": 30,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"num_trials\": 15,\n",
    "}\n",
    "\n",
    "main(\n",
    "    config=config,\n",
    "    df=df,\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=valid_loader,\n",
    "    test_loader=test_loader,\n",
    "    model_cls=LogisticRgressionModel,\n",
    "    feature_dim=8,\n",
    "    gpus_per_trial=1 if torch.cuda.is_available() else 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mbest_result\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_result' is not defined"
     ]
    }
   ],
   "source": [
    "best_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
